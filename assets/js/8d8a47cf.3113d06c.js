"use strict";(self.webpackChunklearning_notes=self.webpackChunklearning_notes||[]).push([[5702],{80991:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>l,toc:()=>o});var a=s(85893),t=s(11151);const i={sidebar_label:"Selection of K",description:"How do we select the number of clusters for K-Means and GMMs?"},r="How Many Clusters?",l={id:"cab420-machine-learning/how-to-select-k",title:"How Many Clusters?",description:"How do we select the number of clusters for K-Means and GMMs?",source:"@site/university/cab420-machine-learning/083-how-to-select-k.md",sourceDirName:"cab420-machine-learning",slug:"/cab420-machine-learning/how-to-select-k",permalink:"/university/cab420-machine-learning/how-to-select-k",draft:!1,unlisted:!1,editUrl:"https://github.com/xiaohai-huang/learning-notes/tree/master/university/cab420-machine-learning/083-how-to-select-k.md",tags:[],version:"current",lastUpdatedBy:"xiaohai-huang",lastUpdatedAt:1654143564,formattedLastUpdatedAt:"02 Jun 2022",sidebarPosition:83,frontMatter:{sidebar_label:"Selection of K",description:"How do we select the number of clusters for K-Means and GMMs?"},sidebar:"university",previous:{title:"Gaussian Mixture Models",permalink:"/university/cab420-machine-learning/gmms"},next:{title:"HAC",permalink:"/university/cab420-machine-learning/hac"}},c={},o=[{value:"Bayesian Information Criterion",id:"bayesian-information-criterion",level:2},{value:"K-Means: Selection of K",id:"k-means-selection-of-k",level:2},{value:"Reconstruction Error",id:"reconstruction-error",level:3},{value:"Approximate BIC",id:"approximate-bic",level:3},{value:"GMM: Selection of K",id:"gmm-selection-of-k",level:2},{value:"Why is K different each time?",id:"why-is-k-different-each-time",level:2},{value:"What Happens When K is Wrong?",id:"what-happens-when-k-is-wrong",level:2},{value:"References",id:"references",level:2}];function h(e){const n=Object.assign({h1:"h1",p:"p",h2:"h2",strong:"strong",h3:"h3",img:"img",ul:"ul",li:"li",pre:"pre",code:"code",a:"a",span:"span",math:"math",semantics:"semantics",mrow:"mrow",mi:"mi",annotation:"annotation",admonition:"admonition"},(0,t.ah)(),e.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"how-many-clusters",children:"How Many Clusters?"}),"\n",(0,a.jsx)(n.p,{children:"K-means and GMMs need us to specify a number of clusters. However specifying the number of clusters can require prior knowledge of the data, or other exploration."}),"\n",(0,a.jsx)(n.h2,{id:"bayesian-information-criterion",children:"Bayesian Information Criterion"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"BIC"})," captures how informative a model is while also considering complexity."]}),"\n",(0,a.jsx)(n.h2,{id:"k-means-selection-of-k",children:"K-Means: Selection of K"}),"\n",(0,a.jsxs)(n.p,{children:["The BIC and it's approximation often returns quite large numbers of clusters, particularly for K-means. As such for K-means the ",(0,a.jsx)(n.strong,{children:"elbow"})," of the reconstruction curve is a well established heuristic to select the number of cluster"]}),"\n",(0,a.jsx)(n.h3,{id:"reconstruction-error",children:"Reconstruction Error"}),"\n",(0,a.jsx)(n.p,{children:"We need a way to measure the error in the system. With K-means, our cost function is the distance between the cluster centres and those points assigned to them."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"elbow example",src:s(61141).Z+"",width:"525",height:"361"})}),"\n",(0,a.jsx)(n.p,{children:"We can see our cost quickly drops and converges towards 0. The more clusters we add, the lower this will go. Because we are creating smaller and smaller groups, each cluster will become more compact, until we get to a point where we have as many clusters as points and each point is its own cluster center."}),"\n",(0,a.jsxs)(n.p,{children:['However, we can select the number of clusters based on the location of the "',(0,a.jsx)(n.strong,{children:"elbow"}),'" in the graph. In our case this is around 5-6 clusters.']}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:'Prior to "elbow" point, we get a large drop for each extra cluster we add.'}),"\n",(0,a.jsx)(n.li,{children:"However, after this point, we see that gain start to drop, so it's effectively not worth adding another cluster to the data."}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="Compute reconstruction errors"',children:"'''\ninertia_ :float\n\nSum of squared distances of samples to their closest cluster center.\n'''\nrecon_error = []\nfor i in range (50):\n    kmeans = KMeans(n_clusters=(i+1), random_state=4).fit(data)\n    recon_error.append(kmeans.inertia_)\n\nfig = plt.figure(figsize=[8, 6])\nax = fig.add_subplot(1, 1, 1)\nax.plot(recon_error)\nax.set_xlabel('Number of Clusters')\nax.set_ylabel('Reconstruction Error');\n"})}),"\n",(0,a.jsx)(n.h3,{id:"approximate-bic",children:"Approximate BIC"}),"\n",(0,a.jsx)(n.p,{children:'We can add a penalty for model complexity to help overcome the limitations of the "elbow method".'}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"#reconstruction-error",children:"Reconstruction error"})," plus a term for ",(0,a.jsx)(n.strong,{children:"model complexity"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["Minimum of curve is the best value of ",(0,a.jsx)(n.span,{className:"math math-inline",children:(0,a.jsxs)(n.span,{className:"katex",children:[(0,a.jsx)(n.span,{className:"katex-mathml",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsx)(n.mrow,{children:(0,a.jsx)(n.mi,{children:"K"})}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"K"})]})})}),(0,a.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(n.span,{className:"base",children:[(0,a.jsx)(n.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.07153em"},children:"K"})]})})]})})]}),"\n",(0,a.jsx)(n.admonition,{type:"info",children:(0,a.jsx)(n.p,{children:"This is based on the idea that we'd like make our model more complex only if that model leads to a substantial improvement."})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"k-means bic",src:s(70429).Z+"",width:"540",height:"375"})}),"\n",(0,a.jsxs)(n.p,{children:["According to the graph above, we can pick ~200 as ",(0,a.jsx)(n.span,{className:"math math-inline",children:(0,a.jsxs)(n.span,{className:"katex",children:[(0,a.jsx)(n.span,{className:"katex-mathml",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsx)(n.mrow,{children:(0,a.jsx)(n.mi,{children:"K"})}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"K"})]})})}),(0,a.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(n.span,{className:"base",children:[(0,a.jsx)(n.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.07153em"},children:"K"})]})})]})}),". However, this approach is somewhat sensitive to scale of data (this impacts reconstruction error)."]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["The value of ",(0,a.jsx)(n.span,{className:"math math-inline",children:(0,a.jsxs)(n.span,{className:"katex",children:[(0,a.jsx)(n.span,{className:"katex-mathml",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsx)(n.mrow,{children:(0,a.jsx)(n.mi,{children:"K"})}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"K"})]})})}),(0,a.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(n.span,{className:"base",children:[(0,a.jsx)(n.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.07153em"},children:"K"})]})})]})})," is very different."]})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="Compute BIC for K-Means"',children:"def compute_approximate_bic(kmeans,X):\n\n    k = numpy.shape(kmeans.cluster_centers_)[0]*(numpy.shape(kmeans.cluster_centers_)[1] + 1)\n    m = len(X)\n\n    approx_bic = m*numpy.log(kmeans.inertia_ / m) + k*numpy.log(m)\n    return approx_bic\n\nbic = []\nfor i in range (400):\n    kmeans = KMeans(n_clusters=(i+1), random_state=4).fit(data)\n    bic.append(compute_approximate_bic(kmeans, numpy.array(data)))\n\nfig = plt.figure(figsize=[8, 6])\nax = fig.add_subplot(1, 1, 1)\nax.plot(bic)\nax.set_xlabel('Number of Clusters')\nax.set_ylabel('Approximate BIC');\n"})}),"\n",(0,a.jsx)(n.h2,{id:"gmm-selection-of-k",children:"GMM: Selection of K"}),"\n",(0,a.jsx)(n.p,{children:"We can use Bayesian Information Criterion (BIC) to determine the number of clusters with a GMM."}),"\n",(0,a.jsx)(n.p,{children:"BIC: combination of model complexity and error"}),"\n",(0,a.jsxs)(n.p,{children:["Minimum curve is the best value of ",(0,a.jsx)(n.span,{className:"math math-inline",children:(0,a.jsxs)(n.span,{className:"katex",children:[(0,a.jsx)(n.span,{className:"katex-mathml",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsx)(n.mrow,{children:(0,a.jsx)(n.mi,{children:"K"})}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"K"})]})})}),(0,a.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(n.span,{className:"base",children:[(0,a.jsx)(n.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.07153em"},children:"K"})]})})]})}),"."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"gmms bic",src:s(65741).Z+"",width:"606",height:"425"})}),"\n",(0,a.jsxs)(n.p,{children:["According to the graph above, we can pick 10 as ",(0,a.jsx)(n.span,{className:"math math-inline",children:(0,a.jsxs)(n.span,{className:"katex",children:[(0,a.jsx)(n.span,{className:"katex-mathml",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsx)(n.mrow,{children:(0,a.jsx)(n.mi,{children:"K"})}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"K"})]})})}),(0,a.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(n.span,{className:"base",children:[(0,a.jsx)(n.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.07153em"},children:"K"})]})})]})}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="Compute BIC for GMMs"',children:"bics = []\nfor i in range (50):\n    gmm = GaussianMixture(i+1, random_state=4)\n    gmm.fit(data)\n    bics.append(gmm.bic(data))\n\nfig = plt.figure(figsize=[8, 6])\nax = fig.add_subplot(1, 1, 1)\nax.plot(bics)\nax.set_xlabel('Number of Clusters')\nax.set_ylabel('BIC');\n"})}),"\n",(0,a.jsx)(n.h2,{id:"why-is-k-different-each-time",children:"Why is K different each time?"}),"\n",(0,a.jsx)(n.p,{children:"K-Means vs GMMs"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["GMMs have more ",(0,a.jsx)(n.a,{href:"/university/cab420-machine-learning/gmms#python",children:"parameters"})," (means,weights, and covariances), so complexity penalties are larger for the same ",(0,a.jsx)(n.span,{className:"math math-inline",children:(0,a.jsxs)(n.span,{className:"katex",children:[(0,a.jsx)(n.span,{className:"katex-mathml",children:(0,a.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(n.semantics,{children:[(0,a.jsx)(n.mrow,{children:(0,a.jsx)(n.mi,{children:"K"})}),(0,a.jsx)(n.annotation,{encoding:"application/x-tex",children:"K"})]})})}),(0,a.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(n.span,{className:"base",children:[(0,a.jsx)(n.span,{className:"strut",style:{height:"0.6833em"}}),(0,a.jsx)(n.span,{className:"mord mathnormal",style:{marginRight:"0.07153em"},children:"K"})]})})]})}),"."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Reconstruction cost is dependent on data scale"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Data that has a very small range will have smaller reconstruction costs."}),"\n",(0,a.jsx)(n.li,{children:'Can lead to big differences between looking at reconstruction curve "elbow" and approximate BIC minimum.'}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"what-happens-when-k-is-wrong",children:"What Happens When K is Wrong?"}),"\n",(0,a.jsx)(n.p,{children:"Two possible errors:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Over-clustering","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"True clusters are split into multiple sub-clusters, i.e. we have too many clusters"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["Under-clustering","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"True clusters are merged into a single cluster, i.e. not enough clusters."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://github.com/xiaohai-huang/cab420-workspace/blob/master/work/machine-learning/week8/CAB420_Clustering_Example_3_How_Many_Clusters.ipynb",children:"QUT Materials"})}),"\n"]})]})}const m=function(e={}){const{wrapper:n}=Object.assign({},(0,t.ah)(),e.components);return n?(0,a.jsx)(n,Object.assign({},e,{children:(0,a.jsx)(h,e)})):h(e)}},65741:(e,n,s)=>{s.d(n,{Z:()=>a});const a=s.p+"assets/images/gmms-bic-125af6fc130b56da4789fab5e319e078.png"},70429:(e,n,s)=>{s.d(n,{Z:()=>a});const a=s.p+"assets/images/k-means-bic-94cf513558caaeea2df17feb84081f76.png"},61141:(e,n,s)=>{s.d(n,{Z:()=>a});const a=s.p+"assets/images/k-means-elbow-bad8d0831176a627ae8c568db0873103.png"},11151:(e,n,s)=>{s.d(n,{Zo:()=>l,ah:()=>i});var a=s(67294);const t=a.createContext({});function i(e){const n=a.useContext(t);return a.useMemo((()=>"function"==typeof e?e(n):{...n,...e}),[n,e])}const r={};function l({components:e,children:n,disableParentContext:s}){let l;return l=s?"function"==typeof e?e({}):e||r:i(e),a.createElement(t.Provider,{value:l},n)}}}]);