"use strict";(self.webpackChunklearning_notes=self.webpackChunklearning_notes||[]).push([[6221],{33092:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>s,metadata:()=>r,toc:()=>d});var t=a(85893),i=a(11151);const s={sidebar_label:"Data Augmentation",title:"Data Augmentation",description:"Deep networks need lots of data. It's one of the more annoying things about them. Collecting data is very painful, and is one of the more annoying things about machine learning. Data augmentation is a partial solution to both these annoyances."},o=void 0,r={id:"cab420-machine-learning/data-augmentation",title:"Data Augmentation",description:"Deep networks need lots of data. It's one of the more annoying things about them. Collecting data is very painful, and is one of the more annoying things about machine learning. Data augmentation is a partial solution to both these annoyances.",source:"@site/university/cab420-machine-learning/053-data-augmentation.mdx",sourceDirName:"cab420-machine-learning",slug:"/cab420-machine-learning/data-augmentation",permalink:"/university/cab420-machine-learning/data-augmentation",draft:!1,unlisted:!1,editUrl:"https://github.com/xiaohai-huang/learning-notes/tree/master/university/cab420-machine-learning/053-data-augmentation.mdx",tags:[],version:"current",lastUpdatedBy:"xiaohai-huang",lastUpdatedAt:1652408919,formattedLastUpdatedAt:"13 May 2022",sidebarPosition:53,frontMatter:{sidebar_label:"Data Augmentation",title:"Data Augmentation",description:"Deep networks need lots of data. It's one of the more annoying things about them. Collecting data is very painful, and is one of the more annoying things about machine learning. Data augmentation is a partial solution to both these annoyances."},sidebar:"university",previous:{title:"Fine Tuning",permalink:"/university/cab420-machine-learning/fine-tuning"},next:{title:"Dimension Reduction",permalink:"/university/cab420-machine-learning/dimension-reduction"}},l={},d=[{value:"Motivations",id:"motivations",level:2},{value:"Guidelines",id:"guidelines",level:2},{value:"Keras Example",id:"keras-example",level:2},{value:"References",id:"references",level:2}];function h(e){const n=Object.assign({p:"p",ul:"ul",li:"li",h2:"h2",strong:"strong",admonition:"admonition",ol:"ol",pre:"pre",code:"code",img:"img",a:"a"},(0,i.ah)(),e.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"Creates a new dataset by applying simple transforms to the data you have."}),"\n",(0,t.jsx)(n.p,{children:"Simple transforms may include:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Rescaling of the image"}),"\n",(0,t.jsx)(n.li,{children:"Rotations"}),"\n",(0,t.jsx)(n.li,{children:"Horizontal/Vertical flips"}),"\n",(0,t.jsx)(n.li,{children:"Adding noise or small color shifts"}),"\n",(0,t.jsx)(n.li,{children:"Translations"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"motivations",children:"Motivations"}),"\n",(0,t.jsx)(n.p,{children:"DCNNs need lots of data. Sometimes this is hard"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Data capture can be expensive."}),"\n",(0,t.jsx)(n.li,{children:"Annotation is also expensive."}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Data variety is key to avoid ",(0,t.jsx)(n.strong,{children:"overfitting"}),". In addition, different data simples can appear very similar."]}),"\n",(0,t.jsx)(n.h2,{id:"guidelines",children:"Guidelines"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Augmentation should not change the meaning of an image."}),"\n",(0,t.jsxs)(n.li,{children:["Characters may change meaning if flipped. (e.g., ",(0,t.jsx)(n.strong,{children:"n"})," vs ",(0,t.jsx)(n.strong,{children:"u"}),")"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Inspect the augmentation results before proceeding."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"If they make sense to you, then it is a good start."}),"\n",(0,t.jsx)(n.li,{children:"If they have changed so much that you cannot tell things apart, you have gone too far."}),"\n"]}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsx)(n.p,{children:"Data augmentation offers a way to get more from limited data. While this can be really powerful, care must be taken to ensure that generated data is still realistic and that it doesn't in some way alter what the ground truth should be. The simplest way to help ensure this is just to inspect the data, and check that your transform is doing what you expect."})}),"\n",(0,t.jsx)(n.h2,{id:"keras-example",children:"Keras Example"}),"\n",(0,t.jsx)(n.p,{children:"Include augmentation directly in the model, we need to:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Remove the input layer from the old model."}),"\n",(0,t.jsx)(n.li,{children:"Crate a new input player, which we will pass to the augmentation function."}),"\n",(0,t.jsx)(n.li,{children:"Pass the output of the augmentation to the rest of the model."}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'data_augmentation = keras.Sequential([\n  layers.experimental.preprocessing.RandomFlip("horizontal"),\n  layers.experimental.preprocessing.RandomRotation(0.05),\n  layers.experimental.preprocessing.RandomZoom(0.025),\n  layers.experimental.preprocessing.RandomTranslation(height_factor=(-0.025, 0.025), width_factor=(-0.025, 0.025))\n])\n\nfig = plt.figure(figsize=[20, 25])\nfor i in range(10):\n    for j in range(10):\n        ax = fig.add_subplot(10, 10, i*10 + (j + 1))\n        augmented_image = data_augmentation(tf.expand_dims(x_train[i,:,:,:],0))\n        plt.imshow(augmented_image[0])\n        plt.axis("off")\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# load model\nmodel = keras.models.load_model('../models/vgg_2stage_MNIST_small.h5')\n# remove first layer, i.e. the input\nmodel.layers.pop(0)\n# create a new input\ninput_layer = keras.Input(shape=(28, 28, 1, ), name='img')\n# pass the input to our augmenter\naugmented = data_augmentation(input_layer)\n# pass the augmented input to the rest of the model\noutput = model(augmented)\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"new_model = keras.Model(inputs=input_layer, outputs=output)\nnew_model.summary()\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'Model: "model_1"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #\n=================================================================\n img (InputLayer)            [(None, 28, 28, 1)]       0\n\n sequential (Sequential)     (None, 28, 28, 1)         0\n\n simple_vgg (Functional)     (None, 10)                810914\n\n=================================================================\nTotal params: 810,914\nTrainable params: 810,354\nNon-trainable params: 560\n_________________________________________________________________\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"data_augmentation.png",src:a(18577).Z+"",width:"846",height:"527"})}),"\n",(0,t.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://github.com/xiaohai-huang/cab420-workspace/blob/master/work/machine-learning/week5/CAB420_DCNNs_Example_6_Fine_Tuning_and_Data_Augmentation.ipynb",children:"QUT Example"})}),"\n"]})]})}const c=function(e={}){const{wrapper:n}=Object.assign({},(0,i.ah)(),e.components);return n?(0,t.jsx)(n,Object.assign({},e,{children:(0,t.jsx)(h,e)})):h(e)}},18577:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/data_augmentation-be9b872b5c7c785dbcc12d1c13f5e46f.png"},11151:(e,n,a)=>{a.d(n,{Zo:()=>r,ah:()=>s});var t=a(67294);const i=t.createContext({});function s(e){const n=t.useContext(i);return t.useMemo((()=>"function"==typeof e?e(n):{...n,...e}),[n,e])}const o={};function r({components:e,children:n,disableParentContext:a}){let r;return r=a?"function"==typeof e?e({}):e||o:s(e),t.createElement(i.Provider,{value:r},n)}}}]);