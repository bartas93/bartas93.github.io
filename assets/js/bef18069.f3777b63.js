"use strict";(self.webpackChunklearning_notes=self.webpackChunklearning_notes||[]).push([[2493],{95670:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>o,contentTitle:()=>c,default:()=>u,frontMatter:()=>s,metadata:()=>l,toc:()=>d});var a=n(85893),t=n(11151),r=n(72796);const s={sidebar_label:"Bias & Variance",title:"Bias and Variance",description:""},c=void 0,l={id:"cab420-machine-learning/bias-and-variance",title:"Bias and Variance",description:"",source:"@site/university/cab420-machine-learning/021-bias-and-variance.mdx",sourceDirName:"cab420-machine-learning",slug:"/cab420-machine-learning/bias-and-variance",permalink:"/university/cab420-machine-learning/bias-and-variance",draft:!1,unlisted:!1,editUrl:"https://github.com/xiaohai-huang/learning-notes/tree/master/university/cab420-machine-learning/021-bias-and-variance.mdx",tags:[],version:"current",lastUpdatedBy:"xiaohai-huang",lastUpdatedAt:1648542549,formattedLastUpdatedAt:"29 Mar 2022",sidebarPosition:21,frontMatter:{sidebar_label:"Bias & Variance",title:"Bias and Variance",description:""},sidebar:"university",previous:{title:"Overfitting",permalink:"/university/cab420-machine-learning/overfitting"},next:{title:"Regularization",permalink:"/university/cab420-machine-learning/regularization"}},o={},d=[{value:"Bias",id:"bias",level:3},{value:"Variance",id:"variance",level:3},{value:"Bias-Variance Tradeoff",id:"bias-variance-tradeoff",level:3},{value:"References",id:"references",level:2}];function h(e){const i=Object.assign({h3:"h3",blockquote:"blockquote",ul:"ul",li:"li",strong:"strong",p:"p",a:"a",img:"img",h2:"h2"},(0,t.ah)(),e.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(r.Z,{src:"https://www.youtube.com/embed/SjQyLhQIXSM",caption:"Bias/Variance"}),"\n",(0,a.jsx)(i.h3,{id:"bias",children:"Bias"}),"\n",(0,a.jsxs)(i.blockquote,{children:["\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"Bias"})," is the difference between a model's estimated values and the \u201ctrue\u201d values for a variable."]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"Bias"})," can be thought of as errors caused by incorrect assumptions in the learning algorithm."]}),"\n",(0,a.jsxs)(i.li,{children:[(0,a.jsx)(i.strong,{children:"Bias"})," can also be introduced through the training data, if the training data is not representative of the population it was drawn from."]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(i.p,{children:["Model with ",(0,a.jsx)(i.strong,{children:"high bias"})," pays very little attention to the training data and oversimplifies the model.\nIt always produces high error on training and test data. In addition, it can lead to ",(0,a.jsx)(i.a,{href:"/university/cab420-machine-learning/overfitting#how-to-detect-overfitting-and-underfitting",children:"underfitting"})," (the model fits the data poorly)."]}),"\n",(0,a.jsx)(i.h3,{id:"variance",children:"Variance"}),"\n",(0,a.jsxs)(i.blockquote,{children:["\n",(0,a.jsx)(i.p,{children:"Variance can be described as the error caused by sensitivity to small variances in the training data set."}),"\n"]}),"\n",(0,a.jsxs)(i.p,{children:["Model with ",(0,a.jsx)(i.strong,{children:"high variance"}),' pays a lot of attention to training data (even "noise") so\ndoes not ',(0,a.jsx)(i.strong,{children:"generalize"})," well on the unseen data. This is associated with ",(0,a.jsx)(i.a,{href:"/university/cab420-machine-learning/overfitting",children:"overfitting"}),"."]}),"\n",(0,a.jsx)(i.h3,{id:"bias-variance-tradeoff",children:"Bias-Variance Tradeoff"}),"\n",(0,a.jsx)(i.p,{children:(0,a.jsx)(i.img,{alt:"tradeoff",src:n(36198).Z+"",width:"614",height:"456"})}),"\n",(0,a.jsx)(i.p,{children:"Decreasing bias will increase variance, and decreasing variance will increase bias."}),"\n",(0,a.jsx)(i.p,{children:"The goal is to use an iterative process to find the balance between the two that minimize the overall error."}),"\n",(0,a.jsx)(i.h2,{id:"references",children:"References"}),"\n",(0,a.jsxs)(i.ul,{children:["\n",(0,a.jsx)(i.li,{children:(0,a.jsx)(i.a,{href:"https://github.com/xiaohai-huang/cab420-workspace/tree/master/work/machine-learning/week2",children:"QUT Resources"})}),"\n",(0,a.jsx)(i.li,{children:(0,a.jsx)(i.a,{href:"https://community.alteryx.com/t5/Data-Science/Bias-Versus-Variance/ba-p/351862",children:"Bias Versus Variance"})}),"\n",(0,a.jsx)(i.li,{children:(0,a.jsx)(i.a,{href:"https://www.youtube.com/watch?v=SjQyLhQIXSM",children:"Bias/Variance (C2W1L02) - Andrew Ng"})}),"\n"]})]})}const u=function(e={}){const{wrapper:i}=Object.assign({},(0,t.ah)(),e.components);return i?(0,a.jsx)(i,Object.assign({},e,{children:(0,a.jsx)(h,e)})):h(e)}},72796:(e,i,n)=>{n.d(i,{Z:()=>t});n(67294);var a=n(85893);const t=function(e){let{src:i="",caption:n=""}=e;return(0,a.jsxs)("div",{children:[(0,a.jsx)("iframe",{style:{width:"100%",height:"350px"},src:i,title:"YouTube video player",frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowFullScreen:!0}),n&&(0,a.jsx)("p",{style:{textAlign:"center"},children:n})]})}},36198:(e,i,n)=>{n.d(i,{Z:()=>a});const a=n.p+"assets/images/tradeoff-eb7ed244bbf301cc820aa8ee404111d2.png"},11151:(e,i,n)=>{n.d(i,{Zo:()=>c,ah:()=>r});var a=n(67294);const t=a.createContext({});function r(e){const i=a.useContext(t);return a.useMemo((()=>"function"==typeof e?e(i):{...i,...e}),[i,e])}const s={};function c({components:e,children:i,disableParentContext:n}){let c;return c=n?"function"==typeof e?e({}):e||s:r(e),a.createElement(t.Provider,{value:c},i)}}}]);