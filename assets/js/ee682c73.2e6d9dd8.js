"use strict";(self.webpackChunklearning_notes=self.webpackChunklearning_notes||[]).push([[6812],{78152:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var t=s(85893),i=s(11151);const a={sidebar_label:"Multi-Task Learning",description:"Multiple outputs from a deep neural network."},r="Multi-Task Learning",l={id:"cab420-machine-learning/multi-task-learning",title:"Multi-Task Learning",description:"Multiple outputs from a deep neural network.",source:"@site/university/cab420-machine-learning/102-multi-task-learning.md",sourceDirName:"cab420-machine-learning",slug:"/cab420-machine-learning/multi-task-learning",permalink:"/university/cab420-machine-learning/multi-task-learning",draft:!1,unlisted:!1,editUrl:"https://github.com/xiaohai-huang/learning-notes/tree/master/university/cab420-machine-learning/102-multi-task-learning.md",tags:[],version:"current",lastUpdatedBy:"xiaohai-huang",lastUpdatedAt:1654530771,formattedLastUpdatedAt:"06 Jun 2022",sidebarPosition:102,frontMatter:{sidebar_label:"Multi-Task Learning",description:"Multiple outputs from a deep neural network."},sidebar:"university",previous:{title:"Auto Encoders",permalink:"/university/cab420-machine-learning/auto-encoders"},next:{title:"Semi-Supervised Learning",permalink:"/university/cab420-machine-learning/semi-supervised-learning"}},o={},c=[{value:"Pros and Cons",id:"pros-and-cons",level:2},{value:"Loss Weights",id:"loss-weights",level:2}];function d(e){const n=Object.assign({h1:"h1",p:"p",h2:"h2",strong:"strong",ul:"ul",li:"li",pre:"pre",code:"code"},(0,i.ah)(),e.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"multi-task-learning",children:"Multi-Task Learning"}),"\n",(0,t.jsx)(n.p,{children:"The same network can usually do different things, we just need to change the output shape and/or loss."}),"\n",(0,t.jsx)(n.h2,{id:"pros-and-cons",children:"Pros and Cons"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Pros"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Usually has a low overhead","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Can just append a couple of extra layers to get another output"}),"\n",(0,t.jsx)(n.li,{children:"Cheaper than having a network for each task"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Usually helps learning","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"One task helps to regularize the other"}),"\n",(0,t.jsxs)(n.li,{children:["Particularly if tasks are ",(0,t.jsx)(n.strong,{children:"related"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Cons"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"We now need two sets of labels"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"loss-weights",children:"Loss Weights"}),"\n",(0,t.jsx)(n.p,{children:"We can change the loss weights to help the network consider all tasks differently."}),"\n",(0,t.jsx)(n.p,{children:"This can be achieved by providing a list or dict of loss weights to the compile command when we build the model."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"model_cnn.compile(loss=['mean_squared_error', keras.losses.SparseCategoricalCrossentropy(from_logits=True)],\n                  loss_weights=[1, 100],\n"})})]})}const h=function(e={}){const{wrapper:n}=Object.assign({},(0,i.ah)(),e.components);return n?(0,t.jsx)(n,Object.assign({},e,{children:(0,t.jsx)(d,e)})):d(e)}},11151:(e,n,s)=>{s.d(n,{Zo:()=>l,ah:()=>a});var t=s(67294);const i=t.createContext({});function a(e){const n=t.useContext(i);return t.useMemo((()=>"function"==typeof e?e(n):{...n,...e}),[n,e])}const r={};function l({components:e,children:n,disableParentContext:s}){let l;return l=s?"function"==typeof e?e({}):e||r:a(e),t.createElement(i.Provider,{value:l},n)}}}]);