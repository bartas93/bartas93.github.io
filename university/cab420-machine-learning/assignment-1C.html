<!doctype html>
<html lang="en-ZA" dir="ltr" class="docs-wrapper plugin-docs plugin-id-university docs-version-current docs-doc-page docs-doc-id-cab420-machine-learning/assignment-1C" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0-beta.0">
<title data-rh="true">Assignment 1C | Xiaohai&#x27;s Mind Palace</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://xiaohai.wiki/university/cab420-machine-learning/assignment-1C"><meta data-rh="true" property="og:locale" content="en_ZA"><meta data-rh="true" name="docusaurus_locale" content="en-ZA"><meta data-rh="true" name="docsearch:language" content="en-ZA"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-university-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-university-current"><meta data-rh="true" property="og:title" content="Assignment 1C | Xiaohai&#x27;s Mind Palace"><meta data-rh="true" name="description" content="Problem 1. Clustering and Recommendations. Problem 2. Multi-Task Learning"><meta data-rh="true" property="og:description" content="Problem 1. Clustering and Recommendations. Problem 2. Multi-Task Learning"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://xiaohai.wiki/university/cab420-machine-learning/assignment-1C"><link data-rh="true" rel="alternate" href="https://xiaohai.wiki/university/cab420-machine-learning/assignment-1C" hreflang="en-ZA"><link data-rh="true" rel="alternate" href="https://xiaohai.wiki/university/cab420-machine-learning/assignment-1C" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://NIXA4HHO8S-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Xiaohai&#39;s Mind Palace RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Xiaohai&#39;s Mind Palace Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Xiaohai&#39;s Mind Palace" href="/opensearch.xml">





<link rel="stylesheet" href="/katex/katex.min.css"><link rel="stylesheet" href="/assets/css/styles.0988872b.css">
<script src="/assets/js/runtime~main.8e9539b3.js" defer="defer"></script>
<script src="/assets/js/main.318ba0af.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE" height="32" width="32" style="border-radius:var(--ifm-global-radius)"><img src="/img/favicon.ico" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU" height="32" width="32" style="border-radius:var(--ifm-global-radius)"></div><b class="navbar__title text--truncate">Mind Palace</b></a><a class="navbar__item navbar__link" href="/docs">Notes</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/university">University</a><a class="navbar__item navbar__link" href="/unity">Unity</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/showcase">Showcase</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/about">About</a><a href="https://github.com/xiaohai-huang/learning-notes" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/"><img src="/img/favicon.ico" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE" height="32" width="32" style="border-radius:var(--ifm-global-radius)"><img src="/img/favicon.ico" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU" height="32" width="32" style="border-radius:var(--ifm-global-radius)"><b>Mind Palace</b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/university">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/university/cab203-discrete-structure">Discrete Structure</a><button aria-label="Expand sidebar category &#x27;Discrete Structure&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/university/cab320-artificial-intelligence">Artifical Intelligence</a><button aria-label="Expand sidebar category &#x27;Artifical Intelligence&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/university/cab420-machine-learning">Machine Learning</a><button aria-label="Collapse sidebar category &#x27;Machine Learning&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/machine-learning-basics">Machine Learning Basics</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/simple-linear-regression">Simple Linear Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/multiple-linear-regression">Multiple Linear Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/prac-1">Practical 1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/overfitting">Overfitting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/bias-and-variance">Bias &amp; Variance</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/regularization">Regularization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/neural-network-components">Neural Network Components</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/resnets">ResNets</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/fine-tuning">Fine Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/data-augmentation">Data Augmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/dimension-reduction">Dimension Reduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/principal-component-analysis">Principal Component Analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/linear-discriminant-analysis">Linear Discriminant Analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/t-SNE">t-SNE</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/siamese">Siamese Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/contrastive-loss">Contrastive Loss</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/triplet-loss">Triplet Loss</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/embedding-size">Embedding Size</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/k-means">K-Means</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/gmms">Gaussian Mixture Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/how-to-select-k">Selection of K</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/hac">HAC</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/dbscan">DBScan</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/evaluating-clustering-performance">Evaluating Clustering Performance</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/diarisation">Diarisation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/auto-encoders">Auto Encoders</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/multi-task-learning">Multi-Task Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/semi-supervised-learning">Semi-Supervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/varitional-auto-encoders">Variational Auto-Encoders</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/assignment-1A">Assignment 1A</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/assignment-1B">Assignment 1B</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/university/cab420-machine-learning/assignment-1C">Assignment 1C</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/university/cab432-search-engine-technology">Search Engine Technoloy</a><button aria-label="Expand sidebar category &#x27;Search Engine Technoloy&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/university/cs24-introduction-to-computer-systems/a-tour-of-computer-systems">Introduction to Computer Systems</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/university/cab420-machine-learning"><span itemprop="name">Machine Learning</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Assignment 1C</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Assignment 1C</h1>
<ul>
<li>Name: Baorong Huang</li>
<li>Student Number: n10172912</li>
<li>assignment extension request (<strong>FORM-AEX-119078</strong>)</li>
</ul>
<p><img loading="lazy" alt="48 hours extension approval" src="/assets/images/ML-1C-48-extension-1-ebf47b3ddfaaa10ce3d1fd0f5edd00f5.png" width="1654" height="2339" class="img_ev3q"></p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="problem-1-clustering-and-recommendations">Problem 1. Clustering and Recommendations<a href="#problem-1-clustering-and-recommendations" class="hash-link" aria-label="Direct link to Problem 1. Clustering and Recommendations" title="Direct link to Problem 1. Clustering and Recommendations">​</a></h2>
<p>Develop a method to cluster users based on their movie viewing preferences.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="discussion-of-clustering-method">Discussion of Clustering Method<a href="#discussion-of-clustering-method" class="hash-link" aria-label="Direct link to Discussion of Clustering Method" title="Direct link to Discussion of Clustering Method">​</a></h3>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="data-to-cluster">Data to Cluster<a href="#data-to-cluster" class="hash-link" aria-label="Direct link to Data to Cluster" title="Direct link to Data to Cluster">​</a></h4>
<p><strong>Description of the data</strong>: I only use the data containing in <code>ratings.csv</code> and <code>movies.csv</code> files. Firstly, I compute the average rating of each movie using the <code>rating.csv</code> file because my goal is to cluster users rather than movies. Secondly, the <code>genres</code> column in <code>movies.csv</code> is split into multiple columns because this is easier to manipulate. Finally, I combined the <code>ratings.csv</code> and <code>movies.csv</code> tables, obtaining a combined table that contains average rating each user has reported for all genres.</p>
<p>The dataset contains 9742 movies and 100836 ratings.</p>
<p><strong>Special treatments (Data manipulation)</strong>:</p>
<ul>
<li>
<p>There are some average ratings that are <code>NaN</code>, which indicates that the user has not watched any movies from this genre. I replace the <code>NaN</code> with 0. Because <code>NaN</code> values suggest that the user does not like this genre and a 0 can be used to represent this dislike relation (they are not a fan of this genre).</p>
</li>
<li>
<p>Remove the &quot;(no genres listed)&quot; column in the combined table. The average rating for movies that don&#x27;t have genres listed cannot provide useful information when clustering users. Because a movie without genres listed cannot tell the cluster algorithm what movies the user prefers to watch or does not want to watch. For example, we would like to cluster users who like to watch &quot;Musical-Children&quot; rather than having a cluster of users who like &quot;Musical-(no genres listed)&quot; which does not make sense. Clustering users who like &quot;(no genres listed)&quot; is meaningless.</p>
</li>
</ul>
<p>After these pre-processing, I plot the t-SNE graph for the dataset.</p>
<p><img loading="lazy" alt="t-SNE" src="/assets/images/t-SNE-for-all-c0caeaddebfecee86fd73c3f950f2452.png" width="488" height="466" class="img_ev3q"></p>
<p>From the t-SNE we can see that: there are some groups of users who have distinct preferences.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="justification-for-the-selected-clustering-method">Justification for the Selected Clustering Method<a href="#justification-for-the-selected-clustering-method" class="hash-link" aria-label="Direct link to Justification for the Selected Clustering Method" title="Direct link to Justification for the Selected Clustering Method">​</a></h4>
<p>The selected clustering method is <strong>Gaussian Mixture Model</strong>.</p>
<p>The reasons are:</p>
<ol>
<li>As a recommendation system, we might want to make recommendations for new users. If we use HAC or DBScan, it is difficult to add new points to clusters after clustering. Because new points can change the clustering results. Therefore, the clustering methods left are K-Means and GMMs as they allow us to make recommendations for new users.</li>
<li>Eliminate K-Means.<!-- -->
<ul>
<li>K-Means can only extracts spherical clusters because each point in a cluster should be near to the center of that cluster. The spherical shape clusters cannot capture user groups effectively as the shape of the cluster will be much more complex.</li>
<li>The clusters cannot <strong>overlap</strong>. By observing the data we can see that there will be a certain amount of overlap between user groups. For example, cluster &quot;Musical-Children&quot; might overlap with cluster &quot;Animation-Musical&quot;.</li>
</ul>
</li>
<li>The advantages of a GMM over K-Means is that we can get <strong>soft assignment</strong> and the <strong>likelihood of each point</strong> for each cluster. With these two properties we can get a better idea of where the user lies, and how close it is to other cluster centers and make use of that to make recommendations. For instance, if a user lies between two clusters according to the likelihood (e.g., [0.21, 0.4, 0.37, 0.02]), we can recommend popular movies from these two clusters (e.g., the second and third cluster) rather than relying on only one cluster.</li>
<li>With GMM we are able to avoid <strong>hard decisions</strong> for as long as possible. Because we can obtain a soft assignment, and carry the uncertainty about which cluster a user belongs to and finally make recommendations based on this information.</li>
</ol>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="selection-of-hyper-parameters">Selection of Hyper-Parameters<a href="#selection-of-hyper-parameters" class="hash-link" aria-label="Direct link to Selection of Hyper-Parameters" title="Direct link to Selection of Hyper-Parameters">​</a></h4>
<p>GMMs need us to specify a number of clusters. Because I don&#x27;t have prior knowledge of the data. I will use the <strong>Bayesian Information Criterion</strong> to determine the number of clusters. BIC is combination of model complexity and error.</p>
<p>By the way, in order to overcome the impact of random variation in the clustering. I ran each clustering step a few times with different random seeds and average the resulting BIC.</p>
<p><img loading="lazy" alt="BIC" src="/assets/images/BIC-19203edb9b106d1aa084067608c1acc2.png" width="516" height="371" class="img_ev3q"></p>
<p>Considering our task, which is to group users into viewing habits, larger numbers of clusters will mean more fine-grained segmentation and more data to analyze. This not necessarily a bad thing (especially for this big user collection where a diverse viewing habits is possible), however for easy visualizing and analyzing we will pick 3. Because the minimum curve is the best value of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span></span></span></span></span>. According to the <strong>BIC</strong> graph above, we can see that the best number of clusters is 3.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="analysis-of-clustering">Analysis of Clustering<a href="#analysis-of-clustering" class="hash-link" aria-label="Direct link to Analysis of Clustering" title="Direct link to Analysis of Clustering">​</a></h3>
<p>We can think of each cluster being a type of viewing habit. As such, we can look at how each cluster (viewing habit) differs from each other to analyzing the clustering results. To achieve this, I drew bar charts for each cluster.</p>
<p><img loading="lazy" alt="cluster centers" src="/assets/images/cluster-centers-ff654606fca04e69cd9fdb47891b10a5.png" width="1432" height="862" class="img_ev3q"></p>
<p>Considering the average rating for &quot;IMAX&quot;, &quot;Film-Noir&quot;, &quot;Animation&quot;, and &quot;Documentary&quot;, we can see a huge variation. These plots suggest that we can use ratings of genre to cluster users. For example, if the a user who has never watched movies from &quot;Film-Noir&quot; we should not recommend movies from &quot;Documentary&quot; because this type of user is assigned to cluster 1 and the user is expected to give a very low rating for &quot;Documentary&quot; movies or even ignore the recommendation.</p>
<p>Instead of manually inspecting these plots, I will compute the histogram intersection. For two histograms that are identical, the intersection will be1. For two that are totally different, the intersection will be 0.</p>
<table><thead><tr><th>Clusters</th><th>Intersection</th></tr></thead><tbody><tr><td>Cluster 1 vs Cluster 2</td><td>0.5</td></tr><tr><td>Cluster 1 vs Cluster 3</td><td>0.666</td></tr><tr><td>Cluster 2 vs Cluster 3</td><td>0.5</td></tr></tbody></table>
<p>The intersection values for these 3 clusters are fairly small, which suggests that the algorithm captures different viewer habits effectively.</p>
<p>Because we have high dimensional data, which is difficult to plot, we will visualize the result using t-SNE.</p>
<p><img loading="lazy" alt="t-SNE for the GMM result" src="/assets/images/t-SNE-for-clusters-2db70156f11bfa5b57c228e2e858d8cb.png" width="1158" height="1118" class="img_ev3q"></p>
<p>What we can see:</p>
<ol>
<li>We have two types of viewing preferences that are significantly different from each other i.e., the yellow and purple clusters. This makes sense because we have clusters that have a intersection value of 0.5. And the difference is likely caused by the different preferences in &quot;Film-Noir&quot; and &quot;Documentary&quot; genre movies.</li>
<li>The yellow and green clusters are located relatively close. This two clusters might contain users who enjoy &quot;Documentary&quot; movies.</li>
</ol>
<p>The t-SNE suggests that there are three different viewer habits in the dataset.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="clustering-recommendations">Clustering Recommendations<a href="#clustering-recommendations" class="hash-link" aria-label="Direct link to Clustering Recommendations" title="Direct link to Clustering Recommendations">​</a></h3>
<p>Below are the movies recommended for the three users with IDs: 4, 42, and 314;</p>
<table><thead><tr><th>User</th><th align="center">Cluster</th><th>Recommendations (movie id)</th></tr></thead><tbody><tr><td>4</td><td align="center">3</td><td>[356, 318, 1210, 4993, 480]</td></tr><tr><td>42</td><td align="center">3</td><td>[1198, 4993, 480, 2858, 1]</td></tr><tr><td>314</td><td align="center">1</td><td>[2571, 231, 4993, 292, 454]</td></tr></tbody></table>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-to-obtain-recommendations">How to Obtain Recommendations<a href="#how-to-obtain-recommendations" class="hash-link" aria-label="Direct link to How to Obtain Recommendations" title="Direct link to How to Obtain Recommendations">​</a></h4>
<p>Steps for obtaining recommendations for a user:</p>
<ol>
<li>Cluster the data into different viewing habits.</li>
<li>Identify the cluster that the user belongs to.</li>
<li>Find the popular movies within the cluster. This is achieved by ordering the movie by the number of watches.</li>
<li>Find the movies that the user has already watched.</li>
<li>Find the set difference between the &quot;Movies in the cluster&quot; and &quot;Movies watched by the user&quot; to obtain a list of movies that the user have never seen.</li>
<li>Because the list has already been ordered by popularity, we can just slice the list to obtain the top-5 or top-3 movies to recommend.</li>
</ol>
<p><strong>Note</strong>: at the step 2 of the algorithm, because GMM give us the likelihoods of a user belongs to clusters. We can do further analysis on the likelihoods returned by the GMM (e.g., <code>gmm.predict_proba(user_4)</code>). For example. if the likelihoods of a user belongs to cluster 1 and cluster 2 are 37% and 42% respectively. We can then modify the algorithm a bit to obtain popular movies from these two clusters rather than obtaining movies from only one cluster.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="users-viewing-history--previous-ratings">Users Viewing History &amp; Previous Ratings<a href="#users-viewing-history--previous-ratings" class="hash-link" aria-label="Direct link to Users Viewing History &amp; Previous Ratings" title="Direct link to Users Viewing History &amp; Previous Ratings">​</a></h4>
<p><img loading="lazy" alt="users previous average ratings" src="/assets/images/users-avg-ratings-hist-7fbf4f79cb1eaf866243d529ed306a1b.png" width="1432" height="862" class="img_ev3q"></p>
<p>In order to check if the recommendations make sense. I pick a few users at random, remove a bunch of the movies that they have seen. Then I find the <strong>intersection</strong> between the movies my system recommended and the movies removed. After that I calculate a metric called <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">Accuracy</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">cc</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em">cy</span></span></span></span></span> to evaluate the performance. And it is defined as follow:</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>A</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>Recommend Movies</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>B</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mtext>Removed Movies</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><mi>A</mi><mo>∩</mo><mi>B</mi><mi mathvariant="normal">∣</mi></mrow><mtext>|A|</mtext></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
A &amp;= \text{Recommend Movies} \\
B &amp;= \text{Removed Movies} \\
Accuracy &amp;= \frac{|A \cap B|}{\text{|A|}}

\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:5.663em;vertical-align:-2.5815em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.0815em"><span style="top:-5.6685em"><span class="pstrut" style="height:3.427em"></span><span class="mord"><span class="mord mathnormal">A</span></span></span><span style="top:-4.1685em"><span class="pstrut" style="height:3.427em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span><span style="top:-2.0815em"><span class="pstrut" style="height:3.427em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="mord mathnormal">cc</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em">cy</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.5815em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.0815em"><span style="top:-5.6685em"><span class="pstrut" style="height:3.427em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord text"><span class="mord">Recommend Movies</span></span></span></span><span style="top:-4.1685em"><span class="pstrut" style="height:3.427em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord text"><span class="mord">Removed Movies</span></span></span></span><span style="top:-2.0815em"><span class="pstrut" style="height:3.427em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord">|A|</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∩</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.5815em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<p><img loading="lazy" alt="recommendation accuracy" src="/assets/images/recommendation-accuracy-aa7e1e0a1df259eadb3ae904e2e016ff.png" width="1446" height="496" class="img_ev3q"></p>
<p>The graph above shows the <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi></mrow><annotation encoding="application/x-tex">Accuracy</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">cc</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em">cy</span></span></span></span></span> values of the recommendations for 100 random users after removing 50 movies they already seen.</p>
<p>What we see is:</p>
<ul>
<li>The recommendation system did not do a good job for a few users. The accuracies of the recommendations are very low. For example, the accuracies for the users with the IDs 89, 567, and 564 are <strong>0</strong>. In order to further investigate on these low-accuracy users. I draw a bar chart below, we can see that these users&#x27; viewing habits are significantly different from other normal users. For instance, user 89 enjoys &quot;Documentary&quot; movies but he had never watched or dislike &quot;Film-Noir&quot; movies. The recommendation system is struggling at this situation.</li>
</ul>
<p><img loading="lazy" alt="low accuracy users" src="/assets/images/low-accuracy-users-49bc4ca29a093d3aa1a5d2776881e7ab.png" width="1432" height="862" class="img_ev3q"></p>
<ul>
<li>However, the recommendation system did a good job overall. The recommendation accuracies for other users are fairly high. This is due to the fact that these users behave normally.</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="problem-2-multi-task-learning">Problem 2. Multi-Task Learning<a href="#problem-2-multi-task-learning" class="hash-link" aria-label="Direct link to Problem 2. Multi-Task Learning" title="Direct link to Problem 2. Multi-Task Learning">​</a></h2>
<p>Using the given data to implement a multi-task deep learning approach
that, given an input image, classifies the traits.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="data-characteristics">Data Characteristics<a href="#data-characteristics" class="hash-link" aria-label="Direct link to Data Characteristics" title="Direct link to Data Characteristics">​</a></h3>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="small-dataset">Small Dataset<a href="#small-dataset" class="hash-link" aria-label="Direct link to Small Dataset" title="Direct link to Small Dataset">​</a></h4>
<p>The training dataset contains <code>520x100x60</code> <em>colorful</em> images. The size of the training set is very small and it is difficult to train a effective deep neural network by simply feeding these data.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="class-imbalance">Class Imbalance<a href="#class-imbalance" class="hash-link" aria-label="Direct link to Class Imbalance" title="Direct link to Class Imbalance">​</a></h4>
<p><img loading="lazy" alt="Class imbalance" src="/assets/images/q2-class-imbalance-14120041538349b0b527fddd4c3af2b9.png" width="877" height="2221" class="img_ev3q"></p>
<p>The dataset contains imbalanced class distribution. This is a situation where the number of observations which belong to a class is significantly large than those belonging to the other classes.</p>
<p>According to the class distribution graph above, we can see:</p>
<ol>
<li><code>torso_type</code>, the number of short torso clothing is significantly greater than short torso clothing.</li>
<li><code>torso_colour</code>, yellow, grey and unknown torso colors are dominating the distribution. We have a lot of unknown labels for torso color.</li>
<li><code>leg_type</code>, long leg clothing is dominating the distribution.</li>
<li><code>leg_colour</code>, the number of examples for colors like green, orange, purple, and white is limited.</li>
</ol>
<p>This imbalanced dataset will make it harder for the model to classify traits. Because DCNNs are usually aimed to improve accuracy by reducing the error so they do not take the class distribution/proportion into consideration.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="missing-data">Missing Data<a href="#missing-data" class="hash-link" aria-label="Direct link to Missing Data" title="Direct link to Missing Data">​</a></h4>
<p>Some labels have the value of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">1</span></span></span></span></span>. This indicates that the labels of these data are missing. Because we only have a very small amount of data to train, it is impractical to drop these <em>unknown</em> data. The number of training examples will become even smaller if we drop samples with <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">1</span></span></span></span></span>. My approach to deal with these <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">1</span></span></span></span></span> labels is semi-supervised learning.</p>
<p>We can treat this as a semi-supervised learning to enable us learn from labeled and unlabeled data.</p>
<p>This is achieved by defining a loss function which does the standard categorical cross entropy, but it will first find any elements that do not have labels and remove them, so it only calculate the loss on those that we have labels for. In order to make this work, we also need to convert the labels into one-hot encodings.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="pre-processing">Pre-processing<a href="#pre-processing" class="hash-link" aria-label="Direct link to Pre-processing" title="Direct link to Pre-processing">​</a></h3>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="split-data">Split Data<a href="#split-data" class="hash-link" aria-label="Direct link to Split Data" title="Direct link to Split Data">​</a></h4>
<p>The provided utils only split the data into training and testing set, which is insufficient to evaluate the model&#x27;s performance during training. Therefore, I further split the training data into two sets. One is training the other one is the validation set. So that I can effectively tune the hyper-parameters during the training.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">validation_split </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">train_x</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">shape </span><span class="token comment" style="color:rgb(106, 153, 85)"># (468, 100, 60, 3)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">val_x</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">shape   </span><span class="token comment" style="color:rgb(106, 153, 85)"># (52, 100, 60, 3)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">test_x</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">shape  </span><span class="token comment" style="color:rgb(106, 153, 85)"># (196, 100, 60, 3)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="one-hot-encoding">One-Hot Encoding<a href="#one-hot-encoding" class="hash-link" aria-label="Direct link to One-Hot Encoding" title="Direct link to One-Hot Encoding">​</a></h4>
<p>As discussed in the <a href="#missing-data">Data Characteristics</a> section, in order to implement a semi-supervised learning task, we need to convert <code>y</code> into one-hot encoding. During the transformation, when we encounter <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">1</span></span></span></span></span>, the label will be replaced with a vector of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn><mi>s</mi></mrow><annotation encoding="application/x-tex">-1s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">1</span><span class="mord mathnormal">s</span></span></span></span></span> to tell the loss function to ignore this example.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="data-augmentation">Data Augmentation<a href="#data-augmentation" class="hash-link" aria-label="Direct link to Data Augmentation" title="Direct link to Data Augmentation">​</a></h4>
<p><img loading="lazy" alt="data augmentation" src="/assets/images/q2-data-augmentation-fea673458dcf17b310814b7d0db734fd.png" width="454" height="578" class="img_ev3q"></p>
<p>Because we only have a small amount of training data. I use data augmentation to generate images to help my model generalize for unseen data.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">ImageDataGenerator</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  </span><span class="token comment" style="color:rgb(106, 153, 85)"># rotate between -3, +3 degrees</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  rotation_range</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">3</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  </span><span class="token comment" style="color:rgb(106, 153, 85)"># horiziontal shift by +/- 1% of the image width</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  width_shift_range</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">0.01</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  </span><span class="token comment" style="color:rgb(106, 153, 85)"># vertical shift by +/- 1% of the image width</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  height_shift_range</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">0.01</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  </span><span class="token comment" style="color:rgb(106, 153, 85)"># range for zooming</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  zoom_range</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">0.01</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  </span><span class="token comment" style="color:rgb(106, 153, 85)"># allow horizontal flips of data</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  horizontal_flip</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The reason why I choose these parameters for data augmentation is that they can generate &quot;new images&quot; for the model to learn and the augmented images are still distinguishable according to the images above.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="model-development-and-hyper-parameter-selection">Model Development and Hyper-parameter Selection<a href="#model-development-and-hyper-parameter-selection" class="hash-link" aria-label="Direct link to Model Development and Hyper-parameter Selection" title="Direct link to Model Development and Hyper-parameter Selection">​</a></h3>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="network-design">Network Design<a href="#network-design" class="hash-link" aria-label="Direct link to Network Design" title="Direct link to Network Design">​</a></h3>
<p>The full network architecture can be found in the <a href="#appendix">Appendix</a>.</p>
<p>Because we only have a small amount of training data, we can pick a pre-trained model and fine-tune the model using this small dataset. The pre-trained model should be a model that has been trained on image related task and original input image of the model should be colorful if possible.</p>
<p>The <strong>ResNet</strong> with <code>&quot;imagenet&quot;</code> weights is a good pre-trained model to fine-tune because it has been trained on image related task and they share the same type of input data. When the model is loaded, we firstly set the <code>trainable</code> property of the parameters of the pre-trained model to <code>False</code> and add a few Dense layers and finally output the results.</p>
<p>However, I decided to build a ResNet from scratch. It is a ResNet that has 3 stages, for each stage there are 3 residual blocks and 8,16,32 convolutional filters respectively.</p>
<p>Finally for each output label (e.g., gender, torso_colour) I create 3 Dense layers with <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi></mrow><annotation encoding="application/x-tex">ReLU</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em">LU</span></span></span></span></span> of sizes 64,32,16 and a output layer which has size of their one-hot encodings.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">outputs </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">for</span><span class="token plain"> label </span><span class="token keyword" style="color:rgb(86, 156, 214)">in</span><span class="token plain"> label_info</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   </span><span class="token comment" style="color:rgb(106, 153, 85)"># 3 Dense layers</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   x </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> name</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string-interpolation string" style="color:rgb(206, 145, 120)">f&quot;pre-</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token string-interpolation interpolation">label</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token string-interpolation string" style="color:rgb(206, 145, 120)">-1&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> activation</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;relu&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">base_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   x </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> name</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string-interpolation string" style="color:rgb(206, 145, 120)">f&quot;pre-</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token string-interpolation interpolation">label</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token string-interpolation string" style="color:rgb(206, 145, 120)">-2&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> activation</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;relu&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">x</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   x </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> name</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string-interpolation string" style="color:rgb(206, 145, 120)">f&quot;pre-</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token string-interpolation interpolation">label</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token string-interpolation string" style="color:rgb(206, 145, 120)">-3&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> activation</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;relu&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">x</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   </span><span class="token comment" style="color:rgb(106, 153, 85)"># output layer which has the size of its one-hot encoding</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   output </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">label_info</span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token plain">label</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> name</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">label</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">x</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   outputs</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">append</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">output</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The <strong>loss function</strong> for each output is the <strong>masked categorical cross entropy</strong> which can ignore the missing data (the key component of the semi-supervised learning). One exception is the output for mask, I would use the <strong>mean squared error</strong> to compare the generated mask and the actual mask.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token comment" style="color:rgb(106, 153, 85)"># semi-supervised cateogorical cross entropy loss. This wil find any rows that have a -1 in the labels</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># and remove them from consideration</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">masked_cce</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">y_true</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> y_pred</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    y_true_masked </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> tf</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">boolean_mask</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">y_true</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> tf</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">reduce_any</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">tf</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">not_equal</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">y_true</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">-</span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    y_pred_masked </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> tf</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">boolean_mask</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">y_pred</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> tf</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">reduce_any</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">tf</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">not_equal</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">y_true</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">-</span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token keyword" style="color:rgb(86, 156, 214)">return</span><span class="token plain"> K</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">mean</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">K</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">categorical_crossentropy</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">y_true_masked</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> y_pred_masked</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> from_logits</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Because this is a multi-task learning, <strong>loss weights</strong> can be added to the model to help our network consider all tasks equally. We can just provide a dictionary of loss weights when we build the model. However, we are not given any information about which output should be optimized ,therefore, I didn&#x27;t change the loss weights.</p>
<p>The training data also contain the information about <strong>mask</strong>, we can pick the output of the <strong>ResNet</strong>(<code>base_model</code>) as the <strong>latent space representation</strong> which contains all the important information needed to represent our original data point. And then attach a <strong>decoder</strong> to this layer to construct a <strong>mask</strong>(semantic segmentation) using the compressed representation. The hope is that the model can learn the spatial relationships between these traits. For example, if the model knows where the leg is then it can classify the leg type or leg clothing color more effectively. Because the model can ignore those irrelevant information by just focusing on the pixels that contain the leg. Due to time constraint, I didn&#x27;t implement this.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="analysis-of-results">Analysis of Results<a href="#analysis-of-results" class="hash-link" aria-label="Direct link to Analysis of Results" title="Direct link to Analysis of Results">​</a></h3>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="gender">Gender<a href="#gender" class="hash-link" aria-label="Direct link to Gender" title="Direct link to Gender">​</a></h4>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">              precision    recall  f1-score   support</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.60</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.67</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.63</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">106</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.55</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.47</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.50</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">90</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    accuracy                           </span><span class="token number" style="color:rgb(181, 206, 168)">0.58</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   macro avg       </span><span class="token number" style="color:rgb(181, 206, 168)">0.57</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.57</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.57</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">weighted avg       </span><span class="token number" style="color:rgb(181, 206, 168)">0.57</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.58</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.57</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img loading="lazy" alt="q2-gender-confusion-matrix" src="data:image/png;base64,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" width="552" height="590" class="img_ev3q"></p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="torso-clothing-type">Torso Clothing Type<a href="#torso-clothing-type" class="hash-link" aria-label="Direct link to Torso Clothing Type" title="Direct link to Torso Clothing Type">​</a></h4>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">              precision    recall  f1-score   support</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.40</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.45</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.43</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">75</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.63</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.58</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.60</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">121</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    accuracy                           </span><span class="token number" style="color:rgb(181, 206, 168)">0.53</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   macro avg       </span><span class="token number" style="color:rgb(181, 206, 168)">0.52</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.52</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.51</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">weighted avg       </span><span class="token number" style="color:rgb(181, 206, 168)">0.54</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.53</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.54</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img loading="lazy" alt="q2 Torso Clothing Type Confusion Matrix" src="data:image/png;base64,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" width="552" height="590" class="img_ev3q"></p>
<table><thead><tr><th>Class</th><th>Predicted</th><th>Actual</th></tr></thead><tbody><tr><td>gender</td><td>0</td><td>0</td></tr><tr><td>torso_type</td><td><strong>short</strong></td><td><strong>long</strong></td></tr><tr><td>torso_colour</td><td>0</td><td>0</td></tr><tr><td>leg_type</td><td>1</td><td>0</td></tr><tr><td>leg_colour</td><td>4</td><td>4</td></tr><tr><td>luggage</td><td>1</td><td>0</td></tr></tbody></table>
<p><img loading="lazy" alt="q2 torso type bad case" src="/assets/images/q2-torso-type-bad-case-id-17-24e9643da7a049287430f21f80504cf7.png" width="295" height="468" class="img_ev3q"></p>
<p>The model misclassifies a long torso clothing as short. One reason to this could be the person is not facing the camera and the person&#x27;s hands is not entirely visible.</p>
<p><strong>Impact on semantic search</strong>: the semantic search might not function well if the person to match is standing in an unexpected position or if the person&#x27;s body parts are not entirely visible.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="torso-clothing-color">Torso Clothing Color<a href="#torso-clothing-color" class="hash-link" aria-label="Direct link to Torso Clothing Color" title="Direct link to Torso Clothing Color">​</a></h4>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">              precision    recall  f1-score   support</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.53</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.78</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.63</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">51</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.30</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.39</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.34</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">23</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">2</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.18</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.17</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.17</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">12</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">3</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.29</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.22</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.25</span><span class="token plain">         </span><span class="token number" style="color:rgb(181, 206, 168)">9</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">4</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.11</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.19</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.14</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">21</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">5</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">         </span><span class="token number" style="color:rgb(181, 206, 168)">5</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">6</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.38</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.43</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.40</span><span class="token plain">         </span><span class="token number" style="color:rgb(181, 206, 168)">7</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">7</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">         </span><span class="token number" style="color:rgb(181, 206, 168)">5</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.67</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.21</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.32</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">19</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">9</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.26</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.17</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.21</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">35</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">          </span><span class="token number" style="color:rgb(181, 206, 168)">10</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">         </span><span class="token number" style="color:rgb(181, 206, 168)">9</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    accuracy                           </span><span class="token number" style="color:rgb(181, 206, 168)">0.36</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   macro avg       </span><span class="token number" style="color:rgb(181, 206, 168)">0.25</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.23</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.22</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">weighted avg       </span><span class="token number" style="color:rgb(181, 206, 168)">0.33</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.36</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.32</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img loading="lazy" alt="q2 Torso Clothing Color Confusion Matrix" src="/assets/images/q2-torso-color-conf-f43712a57a80d9f8869a9b6b74c40db3.png" width="552" height="590" class="img_ev3q"></p>
<p>class imbalance</p>
<p><img loading="lazy" alt="q2 torso clothing color bad case" src="/assets/images/q2-torso-color-bad-case-id-14-0979594ad6057a6dea06290ee0d3b1c9.png" width="295" height="468" class="img_ev3q"></p>
<table><thead><tr><th>Class</th><th>Predicted</th><th>Actual</th></tr></thead><tbody><tr><td>gender</td><td>1</td><td>1</td></tr><tr><td>torso_type</td><td>1</td><td>1</td></tr><tr><td>torso_colour</td><td><strong>pink</strong></td><td><strong>red</strong></td></tr><tr><td>leg_type</td><td>1</td><td>1</td></tr><tr><td>leg_colour</td><td>1</td><td>1</td></tr><tr><td>luggage</td><td>0</td><td>0</td></tr></tbody></table>
<p>The model misclassifies red as pink. The model cannot tell the subtle difference between red and pink effectively. One reason to this is ,<strong>class imbalance</strong>, the number of pink and red torso clothings is limited in the training set.</p>
<p><strong>Impact on semantic search</strong>: if the query is looking for colors that are rare in the training data (e.g., green, orange, purple .etc), then the search will probably fail since the model cannot classify these colors effectively due to the limited amount of training data.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="leg-clothing-type">Leg Clothing Type<a href="#leg-clothing-type" class="hash-link" aria-label="Direct link to Leg Clothing Type" title="Direct link to Leg Clothing Type">​</a></h4>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">              precision    recall  f1-score   support</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.72</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.90</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.80</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">114</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.79</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.50</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.61</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">82</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    accuracy                           </span><span class="token number" style="color:rgb(181, 206, 168)">0.73</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   macro avg       </span><span class="token number" style="color:rgb(181, 206, 168)">0.75</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.70</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.71</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">weighted avg       </span><span class="token number" style="color:rgb(181, 206, 168)">0.75</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.73</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.72</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img loading="lazy" alt="q2 Leg Clothing Type Confusion Matrix" src="data:image/png;base64,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" width="559" height="590" class="img_ev3q"></p>
<p><img loading="lazy" alt="q2 leg clothing type bad case" src="/assets/images/q2-leg-type-bad-case-id-15-f235b1f53162e1de9f88dbe2825ba064.png" width="295" height="468" class="img_ev3q"></p>
<table><thead><tr><th>Class</th><th>Predicted</th><th>Actual</th></tr></thead><tbody><tr><td>gender</td><td>0</td><td>1</td></tr><tr><td>torso_type</td><td>0</td><td>0</td></tr><tr><td>torso_colour</td><td>4</td><td>4</td></tr><tr><td>leg_type</td><td><strong>long</strong></td><td><strong>short</strong></td></tr><tr><td>leg_colour</td><td>4</td><td>4</td></tr><tr><td>luggage</td><td>1</td><td>1</td></tr></tbody></table>
<p>The model misclassifies the short leg clothing as long. One reason to this might be the person is wearing a very short leg clothing, and the model cannot see the short leg clothing, therefore, classify it as a long leg clothing.</p>
<p><strong>Impact on semantic search</strong>: The model might work effectively for people who are wearing very short leg clothing.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="leg-clothing-color">Leg Clothing Color<a href="#leg-clothing-color" class="hash-link" aria-label="Direct link to Leg Clothing Color" title="Direct link to Leg Clothing Color">​</a></h4>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">              precision    recall  f1-score   support</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.52</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.94</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.67</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">69</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.57</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.48</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.52</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">63</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">2</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.50</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.12</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.20</span><span class="token plain">         </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">3</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">         </span><span class="token number" style="color:rgb(181, 206, 168)">7</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">4</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.50</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.26</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.34</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">27</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">6</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">         </span><span class="token number" style="color:rgb(181, 206, 168)">6</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">7</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">         </span><span class="token number" style="color:rgb(181, 206, 168)">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">         </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">9</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.50</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.08</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.13</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">13</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">          </span><span class="token number" style="color:rgb(181, 206, 168)">10</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.00</span><span class="token plain">         </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    accuracy                           </span><span class="token number" style="color:rgb(181, 206, 168)">0.53</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   macro avg       </span><span class="token number" style="color:rgb(181, 206, 168)">0.26</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.19</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.19</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">weighted avg       </span><span class="token number" style="color:rgb(181, 206, 168)">0.49</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.53</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.47</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img loading="lazy" alt="q2 Leg Clothing Color Confusion Matrix" src="/assets/images/q2-leg-color-conf-b6fbf44184074151ef5b0a3058cbe53a.png" width="552" height="590" class="img_ev3q"></p>
<p>caused by class imbalance.</p>
<p><img loading="lazy" alt="q2 leg color bad case-id.4" src="/assets/images/q2-leg-color-bad-case-1769ede960d6aa95640221e9b59078b9.png" width="295" height="468" class="img_ev3q"></p>
<table><thead><tr><th>Class</th><th>Predicted</th><th>Actual</th></tr></thead><tbody><tr><td>gender</td><td>1</td><td>1</td></tr><tr><td>torso_type</td><td>1</td><td>1</td></tr><tr><td>torso_colour</td><td>8</td><td>8</td></tr><tr><td>leg_type</td><td>1</td><td>1</td></tr><tr><td>leg_colour</td><td><strong>red</strong></td><td><strong>black</strong></td></tr><tr><td>luggage</td><td>0</td><td>0</td></tr></tbody></table>
<p>The leg color is classified as red but it should be black. The One reason could that the model cannot tell if the red pixels on the leg area is part of the leg or not. That small amount of red pixels is actually coming from the backpack. The second reason is that the person&#x27;s torso clothing color is <strong>red</strong>, it seems like the model is unable to distinguish torso and leg clothings. The third reason is that this person&#x27;s leg clothing is too short, the model cannot find the leg clothing.</p>
<p><strong>Impact on semantic search</strong>: due to these limitations, we might not be able to match a person if the person is wearing a very short leg clothing or the person is dominant by a color (e.g., red).</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="luggage">Luggage<a href="#luggage" class="hash-link" aria-label="Direct link to Luggage" title="Direct link to Luggage">​</a></h4>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">              precision    recall  f1-score   support</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.68</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.73</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.70</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">135</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">0.27</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.23</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.25</span><span class="token plain">        </span><span class="token number" style="color:rgb(181, 206, 168)">61</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    accuracy                           </span><span class="token number" style="color:rgb(181, 206, 168)">0.57</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   macro avg       </span><span class="token number" style="color:rgb(181, 206, 168)">0.48</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.48</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.48</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">weighted avg       </span><span class="token number" style="color:rgb(181, 206, 168)">0.55</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.57</span><span class="token plain">      </span><span class="token number" style="color:rgb(181, 206, 168)">0.56</span><span class="token plain">       </span><span class="token number" style="color:rgb(181, 206, 168)">196</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img loading="lazy" alt="q2 Luggage Confusion Matrix" src="data:image/png;base64,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" width="552" height="590" class="img_ev3q"></p>
<table><thead><tr><th>Class</th><th>Predicted</th><th>Actual</th></tr></thead><tbody><tr><td>gender</td><td>1</td><td>0</td></tr><tr><td>torso_type</td><td>0</td><td>0</td></tr><tr><td>torso_colour</td><td>0</td><td>4</td></tr><tr><td>leg_type</td><td>0</td><td>0</td></tr><tr><td>leg_colour</td><td>0</td><td>0</td></tr><tr><td>luggage</td><td>0</td><td>1</td></tr></tbody></table>
<p><img loading="lazy" alt="q2 luggage bad case" src="/assets/images/q2-luggage-bad-case-id-18-23a5ebab16abf409b63135f76d4de9ed.png" width="295" height="468" class="img_ev3q"></p>
<p>The model predicts the person is carrying a luggage but he is not.</p>
<p>Reasons why it made the mistake:</p>
<ul>
<li>The person&#x27;s right is acting like he is carrying a luggage.</li>
<li>The intersection between floors looks like a luggage.</li>
<li>The person&#x27;s hand is placing on top of the intersection.</li>
</ul>
<p><strong>Impact on semantic search</strong>: this bad case indicates that the model is likely to be affected by the environment. For example, it cannot tell the difference between a floor texture and a luggage. Secondly, it does not have the sense of depth, the floor is obviously far away from the person&#x27;s right hand but the model cannot spot this.</p>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="jupyter-notebooks">Jupyter Notebooks<a href="#jupyter-notebooks" class="hash-link" aria-label="Direct link to Jupyter Notebooks" title="Direct link to Jupyter Notebooks">​</a></h2>
<ul>
<li><a href="https://github.com/xiaohai-huang/cab420-workspace/blob/master/work/machine-learning/a1c/Q1/Q1-solution.ipynb" target="_blank" rel="noopener noreferrer">Q1 notebook</a></li>
<li><a href="https://github.com/xiaohai-huang/cab420-workspace/blob/master/work/machine-learning/a1c/Q2/assignment1C_Q2.ipynb" target="_blank" rel="noopener noreferrer">Q2 notebook</a></li>
<li><a href="https://xiaohai.wiki/university/cab420-machine-learning/assignment-1C" target="_blank" rel="noopener noreferrer">HTML version of this assignment</a></li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="appendix">Appendix<a href="#appendix" class="hash-link" aria-label="Direct link to Appendix" title="Direct link to Appendix">​</a></h2>
<p>Question 2 Model Architecture</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">Model: </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;simple_resnet_v2&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">__________________________________________________________________________________________________</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Layer </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">type</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">                   Output Shape         Param </span><span class="token comment" style="color:rgb(106, 153, 85)">#     Connected to</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> img </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">InputLayer</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">               </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">3</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                                </span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_106 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">224</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;img[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_94 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">BatchN  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_106[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> ormalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_94 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">     </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_94[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_107 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">72</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_94[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_95 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">BatchN  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_107[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> ormalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_95 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">     </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_95[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_108 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">584</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_95[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_96 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">BatchN  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_108[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> ormalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_96 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">     </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_96[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_110 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">288</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_94[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_109 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">288</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_96[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> add_30 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Add</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">                   </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_110[0][0]&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                                                                  </span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_109[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_97 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">BatchN  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_30[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> ormalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_97 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">     </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_97[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_111 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">264</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_97[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_98 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">BatchN  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_111[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> ormalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_98 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">     </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_98[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_112 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">584</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_98[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_99 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">BatchN  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_112[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> ormalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_99 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">     </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_99[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_113 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">288</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_99[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> add_31 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Add</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">                   </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_30[0][0]&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                                                                  </span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_113[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_100 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_31[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_100 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_100[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_114 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">264</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_100[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_101 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_114[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_101 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_101[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_115 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">584</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_101[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_102 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_115[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_102 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_102[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_116 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">288</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_102[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> add_32 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Add</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">                   </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_31[0][0]&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                                                                  </span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_116[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_103 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_32[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_103 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">100</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">60</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_103[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_117 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">528</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_103[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_104 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_117[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_104 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_104[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_118 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">2320</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_104[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_105 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_118[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_105 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_105[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_120 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">1056</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_32[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_119 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">544</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_105[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> add_33 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Add</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">                   </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_120[0][0]&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                                                                  </span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_119[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_106 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_33[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_106 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_106[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_121 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">528</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_106[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_107 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_121[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_107 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_107[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_122 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">2320</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_107[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_108 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_122[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_108 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_108[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_123 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">544</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_108[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> add_34 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Add</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">                   </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_33[0][0]&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                                                                  </span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_123[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_109 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_34[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_109 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_109[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_124 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">528</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_109[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_110 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_124[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_110 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_110[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_125 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">2320</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_110[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_111 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_125[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_111 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_111[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_126 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">544</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_111[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> add_35 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Add</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">                   </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_34[0][0]&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                                                                  </span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_126[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_112 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_35[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_112 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">50</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">30</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_112[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_127 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">1056</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_112[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_113 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_127[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_113 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_113[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_128 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">9248</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_113[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_114 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_128[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_114 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_114[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_130 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">2112</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_35[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_129 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">2112</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_114[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> add_36 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Add</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">                   </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_130[0][0]&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                                                                  </span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_129[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_115 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">256</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_36[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_115 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_115[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_131 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">2080</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_115[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_116 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_131[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_116 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_116[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_132 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">9248</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_116[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_117 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_132[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_117 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_117[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_133 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">2112</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_117[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> add_37 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Add</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">                   </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_36[0][0]&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                                                                  </span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_133[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_118 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">256</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_37[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_118 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_118[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_134 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">2080</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_118[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_119 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_134[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_119 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_119[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_135 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">9248</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_119[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_120 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_135[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_120 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_120[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> conv2d_136 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Conv2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">2112</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_120[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> add_38 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Add</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">                   </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_37[0][0]&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                                                                  </span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;conv2d_136[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> batch_normalization_121 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Batch  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">  </span><span class="token number" style="color:rgb(181, 206, 168)">256</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;add_38[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> Normalization</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> activation_121 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Activation</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">25</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">15</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">   </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;batch_normalization_121[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> average_pooling2d_4 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">AveragePo  </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">6</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">3</span><span class="token plain">, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">    </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;activation_121[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> oling2D</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> flatten_4 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Flatten</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">1152</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">         </span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;average_pooling2d_4[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-gender-1 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">73792</span><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;flatten_4[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-torso_type-1 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">73792</span><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;flatten_4[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-torso_colour-1 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">     </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">73792</span><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;flatten_4[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-leg_type-1 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">73792</span><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;flatten_4[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-leg_colour-1 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">73792</span><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;flatten_4[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-luggage-1 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">73792</span><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;flatten_4[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-gender-2 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">2080</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-gender-1[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-torso_type-2 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">2080</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-torso_type-1[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-torso_colour-2 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">     </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">2080</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-torso_colour-1[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-leg_type-2 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">2080</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-leg_type-1[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-leg_colour-2 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">2080</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-leg_colour-1[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-luggage-2 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">2080</span><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-luggage-1[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-gender-3 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">528</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-gender-2[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-torso_type-3 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">528</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-torso_type-2[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-torso_colour-3 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">     </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">528</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-torso_colour-2[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-leg_type-3 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">528</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-leg_type-2[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-leg_colour-3 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">528</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-leg_colour-2[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> pre-luggage-3 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">528</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-luggage-2[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> gender </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">                 </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">2</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token number" style="color:rgb(181, 206, 168)">34</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-gender-3[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> torso_type </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">             </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">2</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token number" style="color:rgb(181, 206, 168)">34</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-torso_type-3[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> torso_colour </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">11</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">187</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-torso_colour-3[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> leg_type </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">               </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">2</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token number" style="color:rgb(181, 206, 168)">34</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-leg_type-3[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> leg_colour </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">             </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">11</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">           </span><span class="token number" style="color:rgb(181, 206, 168)">187</span><span class="token plain">         </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-leg_colour-3[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"> luggage </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">                </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">None, </span><span class="token number" style="color:rgb(181, 206, 168)">2</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain">            </span><span class="token number" style="color:rgb(181, 206, 168)">34</span><span class="token plain">          </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;pre-luggage-3[0][0]&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token operator" style="color:rgb(212, 212, 212)">==</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">Total params: </span><span class="token number" style="color:rgb(181, 206, 168)">518,190</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">Trainable params: </span><span class="token number" style="color:rgb(181, 206, 168)">516,734</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">Non-trainable params: </span><span class="token number" style="color:rgb(181, 206, 168)">1,456</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">__________________________________________________________________________________________________</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/xiaohai-huang/learning-notes/tree/master/university/cab420-machine-learning/assignment-1C.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2022-06-07T10:26:59.000Z">07 Jun 2022</time></b> by <b>xiaohai-huang</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/university/cab420-machine-learning/assignment-1B"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Assignment 1B</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/university/cab432-search-engine-technology"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Search Engine Technology</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#problem-1-clustering-and-recommendations" class="table-of-contents__link toc-highlight">Problem 1. Clustering and Recommendations</a><ul><li><a href="#discussion-of-clustering-method" class="table-of-contents__link toc-highlight">Discussion of Clustering Method</a><ul><li><a href="#data-to-cluster" class="table-of-contents__link toc-highlight">Data to Cluster</a></li><li><a href="#justification-for-the-selected-clustering-method" class="table-of-contents__link toc-highlight">Justification for the Selected Clustering Method</a></li><li><a href="#selection-of-hyper-parameters" class="table-of-contents__link toc-highlight">Selection of Hyper-Parameters</a></li></ul></li><li><a href="#analysis-of-clustering" class="table-of-contents__link toc-highlight">Analysis of Clustering</a></li><li><a href="#clustering-recommendations" class="table-of-contents__link toc-highlight">Clustering Recommendations</a><ul><li><a href="#how-to-obtain-recommendations" class="table-of-contents__link toc-highlight">How to Obtain Recommendations</a></li><li><a href="#users-viewing-history--previous-ratings" class="table-of-contents__link toc-highlight">Users Viewing History &amp; Previous Ratings</a></li></ul></li></ul></li><li><a href="#problem-2-multi-task-learning" class="table-of-contents__link toc-highlight">Problem 2. Multi-Task Learning</a><ul><li><a href="#data-characteristics" class="table-of-contents__link toc-highlight">Data Characteristics</a><ul><li><a href="#small-dataset" class="table-of-contents__link toc-highlight">Small Dataset</a></li><li><a href="#class-imbalance" class="table-of-contents__link toc-highlight">Class Imbalance</a></li><li><a href="#missing-data" class="table-of-contents__link toc-highlight">Missing Data</a></li></ul></li><li><a href="#pre-processing" class="table-of-contents__link toc-highlight">Pre-processing</a><ul><li><a href="#split-data" class="table-of-contents__link toc-highlight">Split Data</a></li><li><a href="#one-hot-encoding" class="table-of-contents__link toc-highlight">One-Hot Encoding</a></li><li><a href="#data-augmentation" class="table-of-contents__link toc-highlight">Data Augmentation</a></li></ul></li><li><a href="#model-development-and-hyper-parameter-selection" class="table-of-contents__link toc-highlight">Model Development and Hyper-parameter Selection</a></li><li><a href="#network-design" class="table-of-contents__link toc-highlight">Network Design</a></li><li><a href="#analysis-of-results" class="table-of-contents__link toc-highlight">Analysis of Results</a><ul><li><a href="#gender" class="table-of-contents__link toc-highlight">Gender</a></li><li><a href="#torso-clothing-type" class="table-of-contents__link toc-highlight">Torso Clothing Type</a></li><li><a href="#torso-clothing-color" class="table-of-contents__link toc-highlight">Torso Clothing Color</a></li><li><a href="#leg-clothing-type" class="table-of-contents__link toc-highlight">Leg Clothing Type</a></li><li><a href="#leg-clothing-color" class="table-of-contents__link toc-highlight">Leg Clothing Color</a></li><li><a href="#luggage" class="table-of-contents__link toc-highlight">Luggage</a></li></ul></li></ul></li><li><a href="#jupyter-notebooks" class="table-of-contents__link toc-highlight">Jupyter Notebooks</a></li><li><a href="#appendix" class="table-of-contents__link toc-highlight">Appendix</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs">Notes</a></li><li class="footer__item"><a class="footer__link-item" href="/university">University</a></li><li class="footer__item"><a class="footer__link-item" href="/unity">Unity</a></li><li class="footer__item"><a class="footer__link-item" href="/todos">Todos</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/xiaohai-huang/resources" target="_blank" rel="noopener noreferrer" class="footer__link-item">Resources<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/xiaohai-huang" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/about">About</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Xiaohai's Mind Palace, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>