<!doctype html>
<html lang="en-ZA" dir="ltr" class="docs-wrapper plugin-docs plugin-id-university docs-version-current docs-doc-page docs-doc-id-cab420-machine-learning/assignment-1B" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0-beta.0">
<title data-rh="true">Assignment 1B | Xiaohai&#x27;s Mind Palace</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://xiaohai.wiki/university/cab420-machine-learning/assignment-1B"><meta data-rh="true" property="og:locale" content="en_ZA"><meta data-rh="true" name="docusaurus_locale" content="en-ZA"><meta data-rh="true" name="docsearch:language" content="en-ZA"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-university-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-university-current"><meta data-rh="true" property="og:title" content="Assignment 1B | Xiaohai&#x27;s Mind Palace"><meta data-rh="true" name="description" content="48 hour extension"><meta data-rh="true" property="og:description" content="48 hour extension"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://xiaohai.wiki/university/cab420-machine-learning/assignment-1B"><link data-rh="true" rel="alternate" href="https://xiaohai.wiki/university/cab420-machine-learning/assignment-1B" hreflang="en-ZA"><link data-rh="true" rel="alternate" href="https://xiaohai.wiki/university/cab420-machine-learning/assignment-1B" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://NIXA4HHO8S-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Xiaohai&#39;s Mind Palace RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Xiaohai&#39;s Mind Palace Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Xiaohai&#39;s Mind Palace" href="/opensearch.xml">





<link rel="stylesheet" href="/katex/katex.min.css"><link rel="stylesheet" href="/assets/css/styles.0988872b.css">
<script src="/assets/js/runtime~main.8e9539b3.js" defer="defer"></script>
<script src="/assets/js/main.318ba0af.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/favicon.ico" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE" height="32" width="32" style="border-radius:var(--ifm-global-radius)"><img src="/img/favicon.ico" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU" height="32" width="32" style="border-radius:var(--ifm-global-radius)"></div><b class="navbar__title text--truncate">Mind Palace</b></a><a class="navbar__item navbar__link" href="/docs">Notes</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/university">University</a><a class="navbar__item navbar__link" href="/unity">Unity</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/showcase">Showcase</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/about">About</a><a href="https://github.com/xiaohai-huang/learning-notes" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/"><img src="/img/favicon.ico" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE" height="32" width="32" style="border-radius:var(--ifm-global-radius)"><img src="/img/favicon.ico" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU" height="32" width="32" style="border-radius:var(--ifm-global-radius)"><b>Mind Palace</b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/university">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/university/cab203-discrete-structure">Discrete Structure</a><button aria-label="Expand sidebar category &#x27;Discrete Structure&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/university/cab320-artificial-intelligence">Artifical Intelligence</a><button aria-label="Expand sidebar category &#x27;Artifical Intelligence&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/university/cab420-machine-learning">Machine Learning</a><button aria-label="Collapse sidebar category &#x27;Machine Learning&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/machine-learning-basics">Machine Learning Basics</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/simple-linear-regression">Simple Linear Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/multiple-linear-regression">Multiple Linear Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/prac-1">Practical 1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/overfitting">Overfitting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/bias-and-variance">Bias &amp; Variance</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/regularization">Regularization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/neural-network-components">Neural Network Components</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/resnets">ResNets</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/fine-tuning">Fine Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/data-augmentation">Data Augmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/dimension-reduction">Dimension Reduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/principal-component-analysis">Principal Component Analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/linear-discriminant-analysis">Linear Discriminant Analysis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/t-SNE">t-SNE</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/siamese">Siamese Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/contrastive-loss">Contrastive Loss</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/triplet-loss">Triplet Loss</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/embedding-size">Embedding Size</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/k-means">K-Means</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/gmms">Gaussian Mixture Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/how-to-select-k">Selection of K</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/hac">HAC</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/dbscan">DBScan</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/evaluating-clustering-performance">Evaluating Clustering Performance</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/diarisation">Diarisation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/auto-encoders">Auto Encoders</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/multi-task-learning">Multi-Task Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/semi-supervised-learning">Semi-Supervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/varitional-auto-encoders">Variational Auto-Encoders</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/assignment-1A">Assignment 1A</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/university/cab420-machine-learning/assignment-1B">Assignment 1B</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/university/cab420-machine-learning/assignment-1C">Assignment 1C</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/university/cab432-search-engine-technology">Search Engine Technoloy</a><button aria-label="Expand sidebar category &#x27;Search Engine Technoloy&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/university/cs24-introduction-to-computer-systems/a-tour-of-computer-systems">Introduction to Computer Systems</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/university/cab420-machine-learning"><span itemprop="name">Machine Learning</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Assignment 1B</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Assignment 1B</h1></header><p><img loading="lazy" alt="48 hour extension" src="/assets/images/48-hr-extension-1-0eeecae4d0241145f9b6dc0eb6b0f584.png" width="1654" height="2339" class="img_ev3q"></p>
<ul>
<li>Name: Baorong Huang</li>
<li>Student Number: n10172912</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="problem-1-training-and-adapting-deep-networks">Problem 1. Training and Adapting Deep Networks<a href="#problem-1-training-and-adapting-deep-networks" class="hash-link" aria-label="Direct link to Problem 1. Training and Adapting Deep Networks" title="Direct link to Problem 1. Training and Adapting Deep Networks">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="discussion-of-data-characteristics">Discussion of Data Characteristics<a href="#discussion-of-data-characteristics" class="hash-link" aria-label="Direct link to Discussion of Data Characteristics" title="Direct link to Discussion of Data Characteristics">​</a></h3>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="data-split">Data Split<a href="#data-split" class="hash-link" aria-label="Direct link to Data Split" title="Direct link to Data Split">​</a></h4>
<p>The split of train and test set is not ideal. In the testing set, there are 10, 000 samples total distributed across the 10 classes, however, the training set only contains 1, 000 samples total distributed across the 10 classes. Normally, we want the number of training data to be grater than testing data.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="class-imbalance">Class Imbalance<a href="#class-imbalance" class="hash-link" aria-label="Direct link to Class Imbalance" title="Direct link to Class Imbalance">​</a></h4>
<p><img loading="lazy" alt="q1 data distribution" src="data:image/png;base64,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" width="486" height="466" class="img_ev3q"></p>
<p>The distribution of classes in the training data is imbalance. The histogram shows that number <strong>1</strong> has the largest number of samples in training set and it is significant larger than other classes, which might cause class imbalance. While number <strong>0</strong> has the smallest number of samples.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="variable-range">Variable Range<a href="#variable-range" class="hash-link" aria-label="Direct link to Variable Range" title="Direct link to Variable Range">​</a></h4>
<table><thead><tr><th>stats</th><th>value</th></tr></thead><tbody><tr><td>count</td><td>627200.000000</td></tr><tr><td>mean</td><td>0.465273</td></tr><tr><td>std</td><td>0.223933</td></tr><tr><td>min</td><td>0.007160</td></tr><tr><td>25%</td><td>0.287787</td></tr><tr><td>50%</td><td>0.455336</td></tr><tr><td>75%</td><td>0.618567</td></tr><tr><td>max</td><td>1.000000</td></tr></tbody></table>
<p>Let&#x27;s explore the distribution of the training data (<strong>X</strong>) by computing its descriptive statistics. By analyzing the table above, we can see that input variables are located in the range 0~1 and have a mean of 0.46. This indicates that the input images have been normalized between 0 and 1.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="input-images">Input Images<a href="#input-images" class="hash-link" aria-label="Direct link to Input Images" title="Direct link to Input Images">​</a></h4>
<p><code>train_X.shape == (1000, 32, 32, 3)</code></p>
<p>The training and testing images are 32x32x3 colorful images. However, the architecture of the DCNNs used in this assignment is <code>vgg_3stage_MNIST_bigger</code>, which requires size of input to be 28x28x1 grayscale images. Therefore, the input images have to be pre-processed before feeding into the neural network.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="pre-processing">Pre-processing<a href="#pre-processing" class="hash-link" aria-label="Direct link to Pre-processing" title="Direct link to Pre-processing">​</a></h3>
<p><code>vgg_3stage_MNIST_bigger</code> is selected as the architecture of DCNNs. The input layer of this model requires the data to be the shape of 28x28x1. In order to satisfy the width and height of this input layer. The training and testing data need to be resize and this can be done by calling <code>resize(train_X, (28, 28))</code>. Secondly, since it only requires one color channel, the input images also need to be converted into grayscale images <code>convert_to_grayscale()</code>.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="model-development-and-design">Model Development and Design<a href="#model-development-and-design" class="hash-link" aria-label="Direct link to Model Development and Design" title="Direct link to Model Development and Design">​</a></h3>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="network-design">Network Design<a href="#network-design" class="hash-link" aria-label="Direct link to Network Design" title="Direct link to Network Design">​</a></h4>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockTitle_Ktv7">vgg_3stage_MNIST_bigger</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">inputs </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> keras</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Input</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">shape</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token number" style="color:rgb(181, 206, 168)">28</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">28</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> name</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;img&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">x </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> vgg_net</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">inputs</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token number" style="color:rgb(181, 206, 168)">16</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">64</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token number" style="color:rgb(181, 206, 168)">1024</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">256</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.2</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.2</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">output </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> layers</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Dense</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token number" style="color:rgb(181, 206, 168)">10</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">x</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">model_cnn </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> keras</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">inputs</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">inputs</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> outputs</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">output</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> name</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;simple_vgg&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">model_cnn</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token builtin" style="color:rgb(86, 156, 214)">compile</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">loss</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">keras</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">losses</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">SparseCategoricalCrossentropy</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">from_logits</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">              optimizer</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">keras</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">optimizers</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">RMSprop</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">              metrics</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;accuracy&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># NOTE: these are code not images. I don&#x27;t why they are not selectable in PDF.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This sections covers the design of the network.</p>
<p>The plot of the architecture of the network is attached in the <a href="#q1-network-architecture">appendix</a>.</p>
<p>The network consists of 3 convolution blocks with 20% spatial dropout rate and 2 fully connected block with 20% dropout rate.</p>
<p>For these 3 convolution blocks, each block will firstly performs <strong>two</strong> 2D convolutions, each with 3x3 kernels and the number of filters drawn from <code>[16, 32, 64]</code>. Then followed by <strong>BatchNormalisation</strong> + <strong>ReLU</strong> and 20% of spatial dropout. Finally, a 2x2 max-pooling layer except the last block with 64 filters.</p>
<p>For these 2 fully connected blocks, each block contains a fully connected layer of size drawn from <code>[1024, 256]</code>, followed by a batch-norm + ReLU and a dropout layer with 20% drop out rate.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="data-augmentation">Data Augmentation<a href="#data-augmentation" class="hash-link" aria-label="Direct link to Data Augmentation" title="Direct link to Data Augmentation">​</a></h4>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">datagen </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> ImageDataGenerator</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                            </span><span class="token comment" style="color:rgb(106, 153, 85)"># rotate between -5, +5 degrees</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                            rotation_range</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">5</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                            </span><span class="token comment" style="color:rgb(106, 153, 85)"># horizontal shift by +/- 5% of the image width</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                            width_shift_range</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">0.05</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                            </span><span class="token comment" style="color:rgb(106, 153, 85)"># vertical shift by +/- 5% of the image width</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                            height_shift_range</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">0.05</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                            </span><span class="token comment" style="color:rgb(106, 153, 85)"># range for zooming</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                            zoom_range</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">0.1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                            </span><span class="token comment" style="color:rgb(106, 153, 85)"># what value to place in new pixels, given the nature of our data</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                            </span><span class="token comment" style="color:rgb(106, 153, 85)"># we&#x27;ll set this to a constant value of 0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                            fill_mode</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;constant&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> cval</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">0</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>DCNNs need lots of data to train. In this problem, we only have 1000 training examples, which is insufficient. And this is likely to cause <strong>overfitting</strong>. Data augmentation can be used to overcome this issue as it offers a way to get more from limited data.</p>
<p>A few transforms are applied to the training data:</p>
<ul>
<li>Rotate between -5 and 5 degrees</li>
<li>Horizontal shift by +/- 5% of the image width</li>
<li>Vertical shift by +/- 5% of the image width</li>
<li>Zoom in/out 5% of the image</li>
</ul>
<p>Below are the augmented images. After the inspection, it is clearly that all samples still recognizable as their true class.</p>
<p><img loading="lazy" alt="q1 augmented images" src="/assets/images/q1_augmented_images-721bf2be24fd3e908ef0fedfa7f500fa.png" width="1150" height="1372" class="img_ev3q"></p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="data-used-to-pre-train-the-network">Data Used to Pre-train the Network<a href="#data-used-to-pre-train-the-network" class="hash-link" aria-label="Direct link to Data Used to Pre-train the Network" title="Direct link to Data Used to Pre-train the Network">​</a></h4>
<p><img loading="lazy" alt="q1 mnist" src="data:image/webp;base64,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" width="1280" height="960" class="img_ev3q"></p>
<p>The MNIST database of handwritten digits (see above image) is used to train the selected pre-trained network. These data are very similar to the provided SVHN dataset. Because SVHN is like a real world MNIST and the output classes are the same (10 classes).</p>
<p>The first few layers of the network, which has been trained on MNIST might learn some meaningful representations of the numbers/digits. This is helpful since the number of training examples is limited, and we can freeze first few layers and fine-tune the last few layers to adapt to the SVHN dataset.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="discussion-of-computational-considerations">Discussion of Computational Considerations<a href="#discussion-of-computational-considerations" class="hash-link" aria-label="Direct link to Discussion of Computational Considerations" title="Direct link to Discussion of Computational Considerations">​</a></h3>
<p>See <a href="#q1-network-architecture">vgg_3stage_MNIST_bigger network architecture</a> in appendix. Total params: 3,554,618</p>
<p>If the system has a small memory, I would design a model with less fully connected layers. Because fully connected layers require much more parameters than convolution layers, which require more computation instead.</p>
<p>If I have a <strong>GPU</strong> enabled runtime environment, I would design a model that contain more convolution blocks as it allowed for richer and richer representations until a sufficient number of layers is reached. In addition, GPU can load a huge chunk of matrices data into memory due to the high memory bandwidth, and do fast parallel processing with its thousands of cores, this can significantly reduce the time to train the model and to make inference. Below shows that the <strong>GPU runtime</strong> took 33s, 203s, and 18s to train model 2a, 2b, 2c respectively. And the average time to make a inference is 1.5s which is faster than the time took to make a inference using the SVM model that does not require parallel computing.</p>
<p><img loading="lazy" alt="q1 model comparisons gpu" src="/assets/images/q1_model_comparisons_gpu-10d7e48d05321c83d75462aa3a4ab544.png" width="1446" height="387" class="img_ev3q"></p>
<p>If I have a runtime environment with <strong>CPU</strong> only, I would design a model that contain less convolution blocks. The reason is that CPU is good for linear and complex calculations, but not for simpler and multiple calculations (<strong>convolution blocks</strong>) that require parallel computing. Below shows that the <strong>CPU-Only runtime</strong> took significantly longer to train and test the model. It took roughly 16s to make a inference, which is not acceptable in a production environment.</p>
<p><img loading="lazy" alt="q1 model comparisons cpu" src="/assets/images/q1_model_comparisons_cpu-f01908e11baa8d0a0ea8a3adf9d5da71.png" width="1446" height="387" class="img_ev3q"></p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="analysis-of-results">Analysis of Results<a href="#analysis-of-results" class="hash-link" aria-label="Direct link to Analysis of Results" title="Direct link to Analysis of Results">​</a></h3>
<p><img loading="lazy" alt="q1 model comparisons gpu" src="/assets/images/q1_model_comparisons_gpu-10d7e48d05321c83d75462aa3a4ab544.png" width="1446" height="387" class="img_ev3q"></p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="performance">Performance<a href="#performance" class="hash-link" aria-label="Direct link to Performance" title="Direct link to Performance">​</a></h4>
<p>By observing the graph &quot;Test Accuracy as Model Changes&quot; above, what we see is:</p>
<ul>
<li>The SVM model has the lowest test accuracy 0.2906. And the model is <strong>overfitting</strong>, because its training accuracy is 0.64 and test accuracy is 0.2906.<!-- -->
<ul>
<li>The basic <strong>linear kernel</strong> might not be appropriate for this image classification task.</li>
<li>The training dataset is <strong>imbalanced</strong>, an SVM classifier trained on an imbalanced dataset often produces models which are biased towards the majority class and have low performance on the minority.</li>
</ul>
</li>
<li>The second DCNN model using the data augmentation achieved the best result with test accuracy 0.84. Because data augmentation can generate more images for the network to train, it reduces the chance of overfitting and helps the model generalize well on unseen data.</li>
<li>Among these 3 DCNNs, the last model using fine-tuning achieved the worst result with test accuracy 0.71.<!-- -->
<ul>
<li>MNIST handwritten digit (used by the pre-train model) is a bit different from the digits in SVHM dataset. The latter one is printed number (non-handwritten).</li>
<li>The model failed to utilize 3 color channels of the input images. It only accepts grayscale image. This means that some information are lost.</li>
</ul>
</li>
<li>DCNNs perform better than SVM. Because convolution operations in DCNNs are extremely useful in image classification tasks.</li>
</ul>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="training-time">Training Time<a href="#training-time" class="hash-link" aria-label="Direct link to Training Time" title="Direct link to Training Time">​</a></h4>
<p>By observing the graph &quot;Training Time as Model Changes&quot; above, what we see is:</p>
<ul>
<li>DCNNs took more time to train than SVM.</li>
<li>SVM model took the shortest time to train. Because <code>C</code> parameter is 1, which indicates a small missclassification penalty, speed up the process. <code>kernel=&#x27;linear&#x27;</code> a very basic kernel, also helps to speed up the process.</li>
<li>The second DCNN model using data augmentation is the <strong>slowest</strong> model to train, which took 203.5s to complete the training. This is because it has more images to train. These images are generated by <a href="#data-augmentation">data augmentation techniques</a> such as rotations, scaling, and shifts.</li>
<li>Among these 3 DCNNs, the last DCNN model using fine-tuning is the <strong>fastest</strong> model to train, which only took 18.4s. Unlike the first DCNN model that was trained from scratch it only need to train the last few layers of the network. Because the first few layers already contain some meaningful representation of the digits.</li>
</ul>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="inference-time">Inference Time<a href="#inference-time" class="hash-link" aria-label="Direct link to Inference Time" title="Direct link to Inference Time">​</a></h4>
<p>By observing the graph &quot;Inference Time as Model Changes&quot; above, what we see is:</p>
<ul>
<li>Time taken for DCNNs is roughly the same because these 3 DCNNs are using the same architecture.</li>
<li>Time taken for SVM is longer than DCNN because SVM algorithm does not require parallel computing, which cannot take advantages of GPU.</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="problem-2-person-re-identification">Problem 2. Person Re-Identification<a href="#problem-2-person-re-identification" class="hash-link" aria-label="Direct link to Problem 2. Person Re-Identification" title="Direct link to Problem 2. Person Re-Identification">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="data-characteristics">Data Characteristics<a href="#data-characteristics" class="hash-link" aria-label="Direct link to Data Characteristics" title="Direct link to Data Characteristics">​</a></h3>
<p>The provided training data has 5933 128x64x3 images. They are all cropped. The range of each image is between 0~1, so no one dimension has a bigger range than others, therefore data standardization is unnecessary.</p>
<p>Query and gallery sets are from different camera views.</p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="pre-processing-1">Pre-processing<a href="#pre-processing-1" class="hash-link" aria-label="Direct link to Pre-processing" title="Direct link to Pre-processing">​</a></h3>
<p>Images are converted to grayscale and resized to 64 x 32 images.</p>
<ul>
<li>Grayscale, because it allows us to reduce the dimensionality without really losing a lot of data, and also helps deal with issues such as white balance. It also makes results a bit easier to visualize.</li>
<li>Downsampled, because we need more samples than we have dimensions. The training set only has 5933 samples, which is less than the dimension of each sample (<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>128</mn><mo>×</mo><mn>64</mn><mo>×</mo><mn>3</mn><mo>=</mo><mn>24576</mn></mrow><annotation encoding="application/x-tex">128 \times 64 \times 3=24576</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">128</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">64</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">24576</span></span></span></span></span>). After downsampling, the dimension of each image is <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>64</mn><mo>×</mo><mn>32</mn><mo>=</mo><mn>2048</mn></mrow><annotation encoding="application/x-tex">64 \times 32 = 2048</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">64</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">32</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2048</span></span></span></span></span>, which is less than the samples we have. In addition, without downsampling my PC was unable to train the PCA model since it cannot fit such high dimension data into memory.</li>
<li>Vectorized. This means that all columns have been stacked on top of the other, so rather than being <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>64</mn><mo>×</mo><mn>32</mn></mrow><annotation encoding="application/x-tex">64 \times 32</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">64</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">32</span></span></span></span></span> it&#x27;s <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>2048</mn></mrow><annotation encoding="application/x-tex">1 \times 2048</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2048</span></span></span></span></span>. Because PCA wants a vector per sample. However, for the DCNN model, we still pass images as images to help DCNN to gain some spatial awareness. As such, DCNN can understand things like faces, hairs, cloths, and how they are located relative to each other and combined to form a person overall. Vectorization makes it harder to learn these so it will be turn off when training the DCNN.</li>
<li>Obtaining the &quot;mean person&quot; and subtracting that from person vector. Applying the same subtraction operation to the test data as well.</li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="model-development">Model Development<a href="#model-development" class="hash-link" aria-label="Direct link to Model Development" title="Direct link to Model Development">​</a></h3>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="pca">PCA<a href="#pca" class="hash-link" aria-label="Direct link to PCA" title="Direct link to PCA">​</a></h4>
<p>Below are the reasons why I choose PCA as the non deep learning model.</p>
<ol>
<li>PCA requires data to be aligned, and training data are cropped therefore it satisfies PCA&#x27;s requirement.</li>
<li>For images, not all dimensions are equal. Some are highly informative, others are not useful for the task. In this case, the background is useless, which means that it is not helpful when identifying a person&#x27;s identity. It is good to use PCA to get rid of these useless dimensions.</li>
<li>It can improve visualization. We can visualize our principal components.</li>
</ol>
<h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="visualize-principal-components">Visualize Principal Components<a href="#visualize-principal-components" class="hash-link" aria-label="Direct link to Visualize Principal Components" title="Direct link to Visualize Principal Components">​</a></h5>
<p><img loading="lazy" alt="q2 principal components" src="/assets/images/q2_principal_components-19a9f95e5566d55b951d94bee43f36ec.png" width="1130" height="838" class="img_ev3q"></p>
<p>Above is the visualization of the first 80 principal components.</p>
<p>The first 4 principal components look like humans. They can be seen as the &quot;main component&quot; of the samples in our data. However, as we get further into the components, it becomes harder to interpret.</p>
<h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="cumulative-sum-of-pcas-explained-variance">Cumulative Sum of PCA&#x27;s Explained Variance<a href="#cumulative-sum-of-pcas-explained-variance" class="hash-link" aria-label="Direct link to Cumulative Sum of PCA&#x27;s Explained Variance" title="Direct link to Cumulative Sum of PCA&#x27;s Explained Variance">​</a></h5>
<p><img loading="lazy" alt="Cumulative Sum of PCA&amp;#39;s Explained Variance" src="/assets/images/q2_cumulative_sum_of_pca_explained_var-d534bcdbbf1229d0784642d9e8730df7.png" width="609" height="604" class="img_ev3q"></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token number" style="color:rgb(181, 206, 168)">90</span><span class="token plain">% </span><span class="token keyword" style="color:rgb(86, 156, 214)">in</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">235</span><span class="token plain"> components</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token number" style="color:rgb(181, 206, 168)">95</span><span class="token plain">% </span><span class="token keyword" style="color:rgb(86, 156, 214)">in</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">458</span><span class="token plain"> components</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token number" style="color:rgb(181, 206, 168)">99</span><span class="token plain">% </span><span class="token keyword" style="color:rgb(86, 156, 214)">in</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">1079</span><span class="token plain"> components</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>235 components, 11% of the total dimensions, explain 90% of the variation. We can get 95% with just 458, and 99% with 1079. This indicates that last 1000 dimensions are not contributing much.</p>
<h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="reconstruct-image">Reconstruct Image<a href="#reconstruct-image" class="hash-link" aria-label="Direct link to Reconstruct Image" title="Direct link to Reconstruct Image">​</a></h5>
<p><img loading="lazy" alt="q2 reconstruct id3" src="/assets/images/q2_reconstruct_3-3e2aeefadcd78ed000f88b6cb57f5d46.png" width="1093" height="319" class="img_ev3q"></p>
<p>Using only the first 235 components (90% of the variance), we can see that we lose a lot of the information that can be used to identify a person such as face details. But it captures the main shape (height, cloth) of the person, which is helpful. As wee add more components, we add more details to the person&#x27;s face, but it is still very blur.</p>
<h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="cmc-and-top-n-accuracy">CMC and Top-N Accuracy<a href="#cmc-and-top-n-accuracy" class="hash-link" aria-label="Direct link to CMC and Top-N Accuracy" title="Direct link to CMC and Top-N Accuracy">​</a></h5>
<p><img loading="lazy" alt="q2 PCA CMC" src="/assets/images/q2_PCA_CMC-0a19911912a885176a4d6384ca4c9843.png" width="609" height="496" class="img_ev3q"></p>
<table><thead><tr><th>Top-N</th><th>Accuracy</th></tr></thead><tbody><tr><td>Top 1</td><td>0.04983388704318937</td></tr><tr><td>Top 5</td><td>0.10963455149501661</td></tr><tr><td>Top 10</td><td>0.15614617940199335</td></tr></tbody></table>
<p>The performance is bad. Because the CMC curve took too long to reach 1 (not steep).</p>
<h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="t-sne">t-SNE<a href="#t-sne" class="hash-link" aria-label="Direct link to t-SNE" title="Direct link to t-SNE">​</a></h5>
<p><img loading="lazy" alt="q2 PCA SNE graph" src="/assets/images/q2_pca_sne-78936e983707852fe07f2f2010febad4.png" width="1158" height="1134" class="img_ev3q"></p>
<p>What I can see is that:</p>
<ul>
<li>Samples are not clustered nicely.</li>
<li>There is a big difference between the 90% and 95% version. Because it dropped a lot of terms which impact the data distribution.</li>
<li>The raw pixels and the full transformed data look similar.</li>
</ul>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="siamese-network">Siamese Network<a href="#siamese-network" class="hash-link" aria-label="Direct link to Siamese Network" title="Direct link to Siamese Network">​</a></h4>
<h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="network-design-1">Network Design<a href="#network-design-1" class="hash-link" aria-label="Direct link to Network Design" title="Direct link to Network Design">​</a></h5>
<p><img loading="lazy" alt="q2 DCNN architecture" src="/assets/images/q2_dcnn_architecture-bf4c0a135d4d41f64a040ff5aab91149.png" width="632" height="255" class="img_ev3q"></p>
<p>A Siamese Network with triplet loss is selected as the deep learning method. The siamese branch of the network is a simple VGG like network. The network is trained by taking an anchor image and comparing it with both a positive and a negative sample. The network will try to make the distance between the positive pair less than the negative pair by a specified distance.</p>
<p><img loading="lazy" alt="q2 triplet loss function" src="/assets/images/q2_triple_loss-046777dfa59b5c977ae9c210aa4aa8a8.png" width="664" height="86" class="img_ev3q"></p>
<h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="results">Results<a href="#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">​</a></h5>
<p><img loading="lazy" alt="q2 triplet compare" src="/assets/images/q2_DCNN_triplet_compare-1021015482f6ea7b963130581a6e547d.png" width="1423" height="862" class="img_ev3q"></p>
<p>By examining the predictions made by the network above, it is clear that there is a bigger gap between positive and negative samples. The result of positive samples are pushed to 0 and the result of negative samples are pushed far away from 0.</p>
<p>The distributions below show a clear separation between the positive and negative samples.</p>
<p><img loading="lazy" alt="qw data distribution" src="data:image/png;base64,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" width="710" height="683" class="img_ev3q"></p>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="analysis-of-results-1">Analysis of Results<a href="#analysis-of-results-1" class="hash-link" aria-label="Direct link to Analysis of Results" title="Direct link to Analysis of Results">​</a></h3>
<p><strong>PCA</strong> and <strong>Siamese Network</strong> Top-1, Top-5 and Top 10 accuracy</p>
<table><thead><tr><th>Top-N</th><th>PCA Accuracy</th><th>Siamese Network</th></tr></thead><tbody><tr><td>Top-1</td><td>0.04983388704318937</td><td>0.20930232558139536</td></tr><tr><td>Top-5</td><td>0.10963455149501661</td><td>0.46179401993355484</td></tr><tr><td>Top-10</td><td>0.15614617940199335</td><td>0.5714285714285714</td></tr></tbody></table>
<p><img loading="lazy" alt="q2 CMCs" src="/assets/images/q2_CMCs-d50e302a621ca7b79cb83e0413d26623.png" width="609" height="496" class="img_ev3q"></p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="performance-1">Performance<a href="#performance-1" class="hash-link" aria-label="Direct link to Performance" title="Direct link to Performance">​</a></h4>
<p>The above table and graph show that the Siamese network performs better than the PCA model. Because its Top-1, Top-5 and Top-10 accuracy are all grater than PCA&#x27;s. Secondly, the Siamese network&#x27;s CMC curve is steeper than PCA&#x27;s CMC curve.</p>
<p>Here are some reasons why the Siamese network is better than PCA model.</p>
<h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="spatial-awareness">Spatial Awareness<a href="#spatial-awareness" class="hash-link" aria-label="Direct link to Spatial Awareness" title="Direct link to Spatial Awareness">​</a></h5>
<p>The Siamese network take in images as images and that means that the work gain some spatial awareness. This means that, the network can understand things like faces, hairs, cloths, rotations, and how they are located relative to each other and combined to form a person overall. While, the vectorized images, which are the input of PCA model, can still comprehend the relationship, but it is more challenging.</p>
<h5 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="different-camera-views">Different Camera Views<a href="#different-camera-views" class="hash-link" aria-label="Direct link to Different Camera Views" title="Direct link to Different Camera Views">​</a></h5>
<p>The images are captured in different camera views. This means that the data are not aligned, things like the head. face, foot, .etc, are not at the same place in each image. This makes it very hard for PCA.</p>
<h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="computational-efficiencyruntime">Computational Efficiency/Runtime<a href="#computational-efficiencyruntime" class="hash-link" aria-label="Direct link to Computational Efficiency/Runtime" title="Direct link to Computational Efficiency/Runtime">​</a></h4>
<p><img loading="lazy" alt="q2 runtime comparison" src="/assets/images/q2_runtime_comparison-eafd0721da46acdea5526593d30f4183.png" width="1456" height="387" class="img_ev3q"></p>
<p>Above is the training and inference time taken by these two models.</p>
<p>What I can see is that:</p>
<ul>
<li>PCA model is <strong>faster</strong> than the Siamese network in both training and inference time. Especially in training time, it took 11 seconds for PCA but Siamese network took nearly 20 minutes (10 epochs).<!-- -->
<ul>
<li>During training, the Siamese network use <code>triplet_generator</code> to generate triplet images, which consumes time.</li>
<li>The Siamese branch of the network is a simple VGG like network. This is more computational expensive than PCA model. Since it contains a few convolutional and fully connected layers.</li>
<li>Three images (triplet) are passed into the network simultaneously. This means that for one triplet, the Siamese branch will be executed 3 times to obtain the embedding for each image and then compute the triplet loss.</li>
<li>The base network is built from scratch, the weights are initialized randomly. The time can be reduced by using a pre-train network as base network.</li>
</ul>
</li>
<li>The inference time for both methods is similar. They took 1.2 and 1.6 seconds to make an inference on the training data.<!-- -->
<ul>
<li>During inference, the Siamese network just need to compute the one embedding per sample rather than 3 embeddings for a triplet.</li>
</ul>
</li>
</ul>
<p>The strengths of the Siamese network:</p>
<ul>
<li>High accuracy. It has a Top-5 accuracy of 57%</li>
<li>Quick inference time. The time took to make a inference is similar to PCA model.</li>
</ul>
<p>The weakness of the Siamese network:</p>
<ul>
<li>Too long to train even with <strong>GPU</strong>. It took significantly longer time to train compare to PCA model.</li>
</ul>
<p>The strength of PCA:</p>
<ul>
<li>The results can be visualized.</li>
<li>Faster training and inference time. No GPU is required.</li>
</ul>
<p>The weakness of PCA:</p>
<ul>
<li>The results are pretty inaccurate.</li>
<li>Need more data if the dimension of each sample is high. Otherwise, downsampling is required, which might lose some important details. In this problem, the color of cloth is lost.</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="appendix">Appendix<a href="#appendix" class="hash-link" aria-label="Direct link to Appendix" title="Direct link to Appendix">​</a></h2>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="source-code">Source Code<a href="#source-code" class="hash-link" aria-label="Direct link to Source Code" title="Direct link to Source Code">​</a></h3>
<ul>
<li><a href="https://github.com/xiaohai-huang/cab420-workspace/blob/master/work/machine-learning/a1b/assignment1b-q1.ipynb" target="_blank" rel="noopener noreferrer">Q1 Jupyter Notebook</a></li>
<li><a href="https://github.com/xiaohai-huang/cab420-workspace/blob/master/work/machine-learning/a1b/assignment1b-q2.ipynb" target="_blank" rel="noopener noreferrer">Q2 Jupyter Notebook</a></li>
</ul>
<h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="q1-network-architecture">Q1 Network Architecture<a href="#q1-network-architecture" class="hash-link" aria-label="Direct link to Q1 Network Architecture" title="Direct link to Q1 Network Architecture">​</a></h3>
<p><img loading="lazy" alt="q1 architecture" src="/assets/images/q1_architecture-118a9137370b89eed08c8187d0d4d7c1.png" width="629" height="3061" class="img_ev3q"></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/xiaohai-huang/learning-notes/tree/master/university/cab420-machine-learning/assignment-1B.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2022-05-16T17:47:14.000Z">16 May 2022</time></b> by <b>xiaohai-huang</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/university/cab420-machine-learning/assignment-1A"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Assignment 1A</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/university/cab420-machine-learning/assignment-1C"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Assignment 1C</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#problem-1-training-and-adapting-deep-networks" class="table-of-contents__link toc-highlight">Problem 1. Training and Adapting Deep Networks</a><ul><li><a href="#discussion-of-data-characteristics" class="table-of-contents__link toc-highlight">Discussion of Data Characteristics</a><ul><li><a href="#data-split" class="table-of-contents__link toc-highlight">Data Split</a></li><li><a href="#class-imbalance" class="table-of-contents__link toc-highlight">Class Imbalance</a></li><li><a href="#variable-range" class="table-of-contents__link toc-highlight">Variable Range</a></li><li><a href="#input-images" class="table-of-contents__link toc-highlight">Input Images</a></li></ul></li><li><a href="#pre-processing" class="table-of-contents__link toc-highlight">Pre-processing</a></li><li><a href="#model-development-and-design" class="table-of-contents__link toc-highlight">Model Development and Design</a><ul><li><a href="#network-design" class="table-of-contents__link toc-highlight">Network Design</a></li><li><a href="#data-augmentation" class="table-of-contents__link toc-highlight">Data Augmentation</a></li><li><a href="#data-used-to-pre-train-the-network" class="table-of-contents__link toc-highlight">Data Used to Pre-train the Network</a></li></ul></li><li><a href="#discussion-of-computational-considerations" class="table-of-contents__link toc-highlight">Discussion of Computational Considerations</a></li><li><a href="#analysis-of-results" class="table-of-contents__link toc-highlight">Analysis of Results</a><ul><li><a href="#performance" class="table-of-contents__link toc-highlight">Performance</a></li><li><a href="#training-time" class="table-of-contents__link toc-highlight">Training Time</a></li><li><a href="#inference-time" class="table-of-contents__link toc-highlight">Inference Time</a></li></ul></li></ul></li><li><a href="#problem-2-person-re-identification" class="table-of-contents__link toc-highlight">Problem 2. Person Re-Identification</a><ul><li><a href="#data-characteristics" class="table-of-contents__link toc-highlight">Data Characteristics</a></li><li><a href="#pre-processing-1" class="table-of-contents__link toc-highlight">Pre-processing</a></li><li><a href="#model-development" class="table-of-contents__link toc-highlight">Model Development</a><ul><li><a href="#pca" class="table-of-contents__link toc-highlight">PCA</a></li><li><a href="#siamese-network" class="table-of-contents__link toc-highlight">Siamese Network</a></li></ul></li><li><a href="#analysis-of-results-1" class="table-of-contents__link toc-highlight">Analysis of Results</a><ul><li><a href="#performance-1" class="table-of-contents__link toc-highlight">Performance</a></li><li><a href="#computational-efficiencyruntime" class="table-of-contents__link toc-highlight">Computational Efficiency/Runtime</a></li></ul></li></ul></li><li><a href="#appendix" class="table-of-contents__link toc-highlight">Appendix</a><ul><li><a href="#source-code" class="table-of-contents__link toc-highlight">Source Code</a></li><li><a href="#q1-network-architecture" class="table-of-contents__link toc-highlight">Q1 Network Architecture</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs">Notes</a></li><li class="footer__item"><a class="footer__link-item" href="/university">University</a></li><li class="footer__item"><a class="footer__link-item" href="/unity">Unity</a></li><li class="footer__item"><a class="footer__link-item" href="/todos">Todos</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/xiaohai-huang/resources" target="_blank" rel="noopener noreferrer" class="footer__link-item">Resources<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/xiaohai-huang" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/about">About</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Xiaohai's Mind Palace, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>